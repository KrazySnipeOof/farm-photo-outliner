{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sweet Potato Root Detection & Segmentation with YOLOv8\n",
        "\n",
        "**Tuskegee AIFARMS Agricultural AI Research**\n",
        "\n",
        "This notebook provides a complete training pipeline for sweet potato root detection and instance segmentation using Ultralytics YOLOv8.\n",
        "\n",
        "**Model choice:** We use the **YOLOv8 m-seg** (medium) checkpoint instead of the smaller n (nano) variant to increase model capacity (more parameters and channels) for finer, more accurate segmentation masks. Training and inference APIs are unchanged.\n",
        "\n",
        "## ‚ö†Ô∏è IMPORTANT: NumPy 2.x Fix Required\n",
        "\n",
        "**If you see `AttributeError: _ARRAY_API not found`:**\n",
        "\n",
        "1. **Run Cell 3 FIRST** (NumPy compatibility fix)\n",
        "2. **Restart Kernel** (Kernel ‚Üí Restart)\n",
        "3. Then continue with Cell 4 (Installation)\n",
        "\n",
        "**Or fix from terminal before opening notebook:**\n",
        "```bash\n",
        "pip install 'numpy<2.0' --force-reinstall\n",
        "```\n",
        "\n",
        "See `FIX_NUMPY_ERROR.md` for detailed instructions.\n",
        "\n",
        "## Features\n",
        "- Root-specific preprocessing for soil backgrounds and lighting variations\n",
        "- Custom metrics: root count, area coverage, size distribution\n",
        "- Active learning: low-confidence prediction flagging\n",
        "- Model comparison: YOLOv8 vs Mask R-CNN baseline\n",
        "- Transfer learning from agricultural checkpoints\n",
        "- Production-ready exports (ONNX, TorchScript)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup & Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì Running in local mode (no Google Drive needed)\n"
          ]
        }
      ],
      "source": [
        "# Local setup - no Google Drive needed\n",
        "import os\n",
        "\n",
        "# Check if running in Colab\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    IS_COLAB = True\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    print(\"‚úì Google Drive mounted (Colab mode)\")\n",
        "except ImportError:\n",
        "    IS_COLAB = False\n",
        "    print(\"‚úì Running in local mode (no Google Drive needed)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "FIXING NUMPY 2.X COMPATIBILITY (Must run before other cells)\n",
            "======================================================================\n",
            "Checking NumPy version...\n",
            "Current NumPy version: 1.26.4\n",
            "‚úì NumPy 1.26.4 is compatible (< 2.0)\n",
            "  No fix needed - proceed to next cell\n",
            "======================================================================\n",
            "IMPORTANT: If NumPy was downgraded, RESTART KERNEL before continuing!\n",
            "  Kernel -> Restart & Run All\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# CRITICAL FIX: NumPy 2.x Compatibility Issue\n",
        "# This MUST run before any other imports to fix NumPy 2.x / opencv-python incompatibility\n",
        "# Run this cell FIRST if you see _ARRAY_API errors\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "import json\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"FIXING NUMPY 2.X COMPATIBILITY (Must run before other cells)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Check NumPy version using pip (without importing numpy)\n",
        "print(\"Checking NumPy version...\")\n",
        "result = subprocess.run(\n",
        "    [sys.executable, '-m', 'pip', 'show', 'numpy'],\n",
        "    capture_output=True,\n",
        "    text=True,\n",
        "    timeout=30\n",
        ")\n",
        "\n",
        "numpy_installed = result.returncode == 0\n",
        "numpy_version = None\n",
        "\n",
        "if numpy_installed:\n",
        "    # Parse version from pip show output\n",
        "    for line in result.stdout.split('\\n'):\n",
        "        if line.startswith('Version:'):\n",
        "            numpy_version = line.split(':', 1)[1].strip()\n",
        "            break\n",
        "    \n",
        "    if numpy_version:\n",
        "        major_version = int(numpy_version.split('.')[0])\n",
        "        print(f\"Current NumPy version: {numpy_version}\")\n",
        "        \n",
        "        if major_version >= 2:\n",
        "            print(f\"\\n‚ö† CRITICAL: NumPy {numpy_version} is incompatible with opencv-python!\")\n",
        "            print(\"  opencv-python was compiled for NumPy 1.x and will fail with _ARRAY_API error\")\n",
        "            print(\"\\n  Downgrading NumPy to < 2.0...\")\n",
        "            \n",
        "            # Clear any cached imports first\n",
        "            modules_to_clear = ['numpy', 'cv2', 'ultralytics', 'opencv']\n",
        "            for mod in modules_to_clear:\n",
        "                if mod in sys.modules:\n",
        "                    del sys.modules[mod]\n",
        "            \n",
        "            # Force downgrade NumPy (without dependencies to avoid conflicts)\n",
        "            print(\"  Installing NumPy < 2.0...\")\n",
        "            fix_result = subprocess.run(\n",
        "                [sys.executable, '-m', 'pip', 'install', 'numpy<2.0', '--force-reinstall'],\n",
        "                capture_output=True,\n",
        "                text=True,\n",
        "                timeout=180\n",
        "            )\n",
        "            \n",
        "            if fix_result.returncode == 0:\n",
        "                # Verify the fix\n",
        "                verify_result = subprocess.run(\n",
        "                    [sys.executable, '-m', 'pip', 'show', 'numpy'],\n",
        "                    capture_output=True,\n",
        "                    text=True,\n",
        "                    timeout=30\n",
        "                )\n",
        "                if verify_result.returncode == 0:\n",
        "                    for line in verify_result.stdout.split('\\n'):\n",
        "                        if line.startswith('Version:'):\n",
        "                            new_version = line.split(':', 1)[1].strip()\n",
        "                            print(f\"\\n‚úì SUCCESS: NumPy downgraded to {new_version}\")\n",
        "                            print(\"  IMPORTANT: Restart kernel now, then proceed to Cell 4 (Installation)\")\n",
        "                            print(\"  In Jupyter: Kernel -> Restart & Run All\")\n",
        "                            break\n",
        "                else:\n",
        "                    print(\"\\n‚úì NumPy downgrade completed (verification pending)\")\n",
        "            else:\n",
        "                print(f\"\\n‚úó Automatic fix failed. Error:\")\n",
        "                if fix_result.stderr:\n",
        "                    error_msg = fix_result.stderr[:500]\n",
        "                    print(f\"  {error_msg}\")\n",
        "                print(f\"\\n  Please run manually in terminal:\")\n",
        "                print(f\"  {sys.executable} -m pip install 'numpy<2.0' --force-reinstall\")\n",
        "        else:\n",
        "            print(f\"‚úì NumPy {numpy_version} is compatible (< 2.0)\")\n",
        "            print(\"  No fix needed - proceed to next cell\")\n",
        "    else:\n",
        "        print(\"‚ö† Could not determine NumPy version\")\n",
        "else:\n",
        "    print(\"NumPy not installed - will be installed with correct version (< 2.0) in next cell\")\n",
        "    # Pre-install NumPy < 2.0 to avoid issues\n",
        "    print(\"Pre-installing NumPy < 2.0...\")\n",
        "    pre_result = subprocess.run(\n",
        "        [sys.executable, '-m', 'pip', 'install', 'numpy<2.0'],\n",
        "        capture_output=True,\n",
        "        text=True,\n",
        "        timeout=120\n",
        "    )\n",
        "    if pre_result.returncode == 0:\n",
        "        print(\"‚úì NumPy < 2.0 pre-installed\")\n",
        "    else:\n",
        "        print(\"‚ö† Pre-installation failed, will try again in next cell\")\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"IMPORTANT: If NumPy was downgraded, RESTART KERNEL before continuing!\")\n",
        "print(\"  Kernel -> Restart & Run All\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì All required packages are installed (local mode)\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies with exact versions\n",
        "# In Colab, packages will be installed; locally, check if installed\n",
        "import subprocess\n",
        "import sys\n",
        "import importlib\n",
        "\n",
        "def install_package(package, use_exact_version=True):\n",
        "    \"\"\"Install a package with error handling\"\"\"\n",
        "    try:\n",
        "        if use_exact_version:\n",
        "            result = subprocess.run(\n",
        "                [sys.executable, '-m', 'pip', 'install', package],\n",
        "                capture_output=True,\n",
        "                text=True,\n",
        "                check=False\n",
        "            )\n",
        "            if result.returncode == 0:\n",
        "                return True, None\n",
        "            else:\n",
        "                # Try without version pin if exact version fails\n",
        "                if '==' in package:\n",
        "                    pkg_name = package.split('==')[0]\n",
        "                    print(f\"    ‚ö† Exact version failed, trying latest: {pkg_name}\")\n",
        "                    return install_package(pkg_name, use_exact_version=False)\n",
        "                return False, result.stderr\n",
        "        else:\n",
        "            result = subprocess.run(\n",
        "                [sys.executable, '-m', 'pip', 'install', package],\n",
        "                capture_output=True,\n",
        "                text=True,\n",
        "                check=False\n",
        "            )\n",
        "            return result.returncode == 0, result.stderr if result.returncode != 0 else None\n",
        "    except Exception as e:\n",
        "        return False, str(e)\n",
        "\n",
        "if IS_COLAB:\n",
        "    # Colab: install packages using subprocess (works in notebooks)\n",
        "    packages = [\n",
        "        'ultralytics==8.1.0', 'roboflow==1.1.1', 'torch==2.1.0', 'torchvision==0.16.0',\n",
        "        'opencv-python==4.8.1.78', 'matplotlib==3.8.2', 'seaborn==0.13.0',\n",
        "        'pandas==2.1.4', 'numpy==1.24.3', 'tqdm==4.66.1', 'pyyaml==6.0.1',\n",
        "        'onnx==1.15.0', 'onnxruntime==1.16.3'\n",
        "    ]\n",
        "    for pkg in packages:\n",
        "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', pkg, '-q'])\n",
        "    print(\"‚úì All dependencies installed (Colab)\")\n",
        "else:\n",
        "    # Local: check if packages are installed\n",
        "    required = {\n",
        "        'torch': 'torch', \n",
        "        'torchvision': 'torchvision', \n",
        "        'ultralytics': 'ultralytics', \n",
        "        'cv2': 'opencv-python', \n",
        "        'yaml': 'pyyaml', \n",
        "        'pandas': 'pandas', \n",
        "        'numpy': 'numpy', \n",
        "        'matplotlib': 'matplotlib', \n",
        "        'seaborn': 'seaborn', \n",
        "        'tqdm': 'tqdm'\n",
        "    }\n",
        "    missing = []\n",
        "    for module_name, package_name in required.items():\n",
        "        try:\n",
        "            if module_name == 'cv2':\n",
        "                importlib.import_module('cv2')\n",
        "            else:\n",
        "                importlib.import_module(module_name)\n",
        "        except ImportError:\n",
        "            missing.append(package_name)\n",
        "    \n",
        "    if missing:\n",
        "        print(f\"‚ö† Missing packages: {missing}\")\n",
        "        print(\"\\nInstalling missing packages...\")\n",
        "        \n",
        "        # Priority order: \n",
        "        # 1. numpy first (needed by opencv-python and others)\n",
        "        # 2. torch and torchvision (large dependencies)\n",
        "        # 3. opencv-python (after numpy to avoid version conflicts)\n",
        "        # 4. ultralytics (depends on torch)\n",
        "        # 5. Others\n",
        "        priority_order = ['numpy', 'torch', 'torchvision', 'opencv-python', 'ultralytics']\n",
        "        other_packages = [pkg for pkg in missing if pkg not in priority_order]\n",
        "        ordered_missing = [pkg for pkg in priority_order if pkg in missing] + other_packages\n",
        "        \n",
        "        # CRITICAL: Check and fix NumPy version first (NumPy 2.x breaks opencv-python)\n",
        "        print(\"  Checking NumPy version compatibility...\")\n",
        "        try:\n",
        "            import numpy\n",
        "            numpy_version = numpy.__version__\n",
        "            major_version = int(numpy_version.split('.')[0])\n",
        "            if major_version >= 2:\n",
        "                print(f\"  ‚ö† NumPy {numpy_version} detected - downgrading to < 2.0 for opencv-python compatibility\")\n",
        "                subprocess.run([sys.executable, '-m', 'pip', 'install', 'numpy<2.0', '--force-reinstall', '--quiet'],\n",
        "                             check=False, timeout=120)\n",
        "                print(\"  ‚úì NumPy downgraded\")\n",
        "        except:\n",
        "            pass  # NumPy not installed yet, will install correct version\n",
        "        \n",
        "        # Try installing from requirements.txt first (faster if it works)\n",
        "        if os.path.exists('requirements.txt'):\n",
        "            print(\"  Attempting to install from requirements.txt...\")\n",
        "            result = subprocess.run(\n",
        "                [sys.executable, '-m', 'pip', 'install', '-r', 'requirements.txt'],\n",
        "                capture_output=True,\n",
        "                text=True,\n",
        "                check=False\n",
        "            )\n",
        "            if result.returncode == 0:\n",
        "                print(\"  ‚úì Installed from requirements.txt\")\n",
        "                # Ensure NumPy < 2.0 after installation\n",
        "                try:\n",
        "                    import numpy\n",
        "                    if int(numpy.__version__.split('.')[0]) >= 2:\n",
        "                        print(\"  ‚ö† Ensuring NumPy < 2.0...\")\n",
        "                        subprocess.run([sys.executable, '-m', 'pip', 'install', 'numpy<2.0', '--force-reinstall', '--quiet'],\n",
        "                                     check=False, timeout=120)\n",
        "                except:\n",
        "                    pass\n",
        "                # Re-check what's still missing\n",
        "                still_missing = []\n",
        "                for module_name, package_name in required.items():\n",
        "                    try:\n",
        "                        if module_name == 'cv2':\n",
        "                            importlib.import_module('cv2')\n",
        "                        else:\n",
        "                            importlib.import_module(module_name)\n",
        "                    except ImportError:\n",
        "                        still_missing.append(package_name)\n",
        "                if not still_missing:\n",
        "                    print(\"‚úì All packages installed successfully!\")\n",
        "                else:\n",
        "                    print(f\"  ‚ö† Some packages still missing: {still_missing}\")\n",
        "                    ordered_missing = [pkg for pkg in priority_order if pkg in still_missing] + [pkg for pkg in still_missing if pkg not in priority_order]\n",
        "            else:\n",
        "                print(f\"  ‚ö† Installation from requirements.txt failed, installing individually...\")\n",
        "                print(f\"  Error: {result.stderr[:200] if result.stderr else 'Unknown error'}\")\n",
        "        \n",
        "        # Install packages individually with special handling for numpy/opencv conflict\n",
        "        failed_packages = []\n",
        "        for pkg in ordered_missing:\n",
        "            print(f\"  Installing {pkg}...\", end=' ')\n",
        "            # Get version from requirements.txt if available\n",
        "            pkg_with_version = pkg\n",
        "            if os.path.exists('requirements.txt'):\n",
        "                with open('requirements.txt', 'r') as f:\n",
        "                    for line in f:\n",
        "                        line = line.strip()\n",
        "                        if line and not line.startswith('#') and '==' in line:\n",
        "                            req_pkg = line.split('==')[0].strip().lower()\n",
        "                            if req_pkg == pkg.lower() or req_pkg.replace('-', '_') == pkg.lower().replace('-', '_'):\n",
        "                                pkg_with_version = line.split('#')[0].strip()\n",
        "                                break\n",
        "            \n",
        "            # Special handling for numpy/opencv-python compatibility\n",
        "            if pkg == 'opencv-python':\n",
        "                # CRITICAL: Ensure numpy < 2.0 (opencv-python doesn't work with NumPy 2.x)\n",
        "                try:\n",
        "                    import numpy\n",
        "                    numpy_version = numpy.__version__\n",
        "                    major_version = int(numpy_version.split('.')[0])\n",
        "                    if major_version >= 2:\n",
        "                        print(f\"\\n    ‚ö† NumPy {numpy_version} detected - downgrading to < 2.0\")\n",
        "                        subprocess.run([sys.executable, '-m', 'pip', 'install', 'numpy<2.0', '--force-reinstall', '--quiet'],\n",
        "                                     check=False, timeout=120)\n",
        "                except:\n",
        "                    # NumPy not installed, install compatible version\n",
        "                    subprocess.run([sys.executable, '-m', 'pip', 'install', 'numpy<2.0', '--quiet'],\n",
        "                                 check=False, timeout=120)\n",
        "            \n",
        "            success, error = install_package(pkg_with_version)\n",
        "            if success:\n",
        "                print(\"‚úì\")\n",
        "                # After installing opencv-python, ensure numpy < 2.0\n",
        "                if pkg == 'opencv-python':\n",
        "                    try:\n",
        "                        import numpy\n",
        "                        if int(numpy.__version__.split('.')[0]) >= 2:\n",
        "                            print(f\"    ‚ö† Fixing NumPy version...\")\n",
        "                            subprocess.run([sys.executable, '-m', 'pip', 'install', 'numpy<2.0', '--force-reinstall', '--quiet'],\n",
        "                                         check=False, timeout=120)\n",
        "                    except:\n",
        "                        pass\n",
        "            else:\n",
        "                print(\"‚úó\")\n",
        "                failed_packages.append((pkg, error))\n",
        "        \n",
        "        if failed_packages:\n",
        "            print(f\"\\n‚ö† Failed to install {len(failed_packages)} package(s):\")\n",
        "            for pkg, error in failed_packages:\n",
        "                print(f\"  - {pkg}\")\n",
        "                if error:\n",
        "                    error_lines = error.split('\\n')[:3]  # Show first 3 lines of error\n",
        "                    for line in error_lines:\n",
        "                        if line.strip():\n",
        "                            print(f\"    {line[:100]}\")\n",
        "            print(f\"\\nüí° Try installing manually:\")\n",
        "            print(f\"   pip install {' '.join([pkg for pkg, _ in failed_packages])}\")\n",
        "        else:\n",
        "            print(\"\\n‚úì All missing packages installed successfully!\")\n",
        "    else:\n",
        "        print(\"‚úì All required packages are installed (local mode)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Importing required packages...\n",
            "  ‚úì numpy 1.26.4\n",
            "  ‚úì cv2 (opencv-python)\n",
            "  ‚úì torch\n",
            "  ‚úì torchvision\n",
            "  ‚úì matplotlib\n",
            "  ‚úì seaborn\n",
            "  ‚úì pandas\n",
            "  ‚úì yaml (pyyaml)\n",
            "  ‚úì tqdm\n",
            "  ‚úì ultralytics\n",
            "  ‚úì ONNX (optional - for model export)\n",
            "\n",
            "‚úì All required packages imported successfully!\n",
            "‚úì PyTorch version: 2.6.0+cu124\n",
            "‚úì CUDA available: True\n",
            "‚úì GPU: NVIDIA GeForce RTX 4070 Laptop GPU\n",
            "‚úì CUDA version: 12.4\n"
          ]
        }
      ],
      "source": [
        "# Import libraries\n",
        "# Check if packages are installed before importing\n",
        "import sys\n",
        "\n",
        "# Track which imports succeed\n",
        "failed_imports = []\n",
        "\n",
        "print(\"Importing required packages...\")\n",
        "\n",
        "# CRITICAL: Import numpy FIRST before cv2 to avoid _ARRAY_API errors\n",
        "# Also check for NumPy 2.x compatibility issue\n",
        "try:\n",
        "    import numpy as np\n",
        "    numpy_version = np.__version__\n",
        "    major_version = int(numpy_version.split('.')[0])\n",
        "    if major_version >= 2:\n",
        "        print(f\"  ‚ö† NumPy {numpy_version} detected (incompatible with opencv-python)\")\n",
        "        print(\"     Downgrading to NumPy < 2.0...\")\n",
        "        import subprocess\n",
        "        subprocess.run([sys.executable, '-m', 'pip', 'install', 'numpy<2.0', '--force-reinstall', '--quiet'],\n",
        "                     check=False, timeout=120)\n",
        "        # Reload numpy\n",
        "        import importlib\n",
        "        if 'numpy' in sys.modules:\n",
        "            del sys.modules['numpy']\n",
        "        import numpy as np\n",
        "        print(f\"  ‚úì numpy {np.__version__} (downgraded)\")\n",
        "    else:\n",
        "        print(f\"  ‚úì numpy {numpy_version}\")\n",
        "except ImportError:\n",
        "    print(\"  ‚úó numpy - not installed\")\n",
        "    failed_imports.append(('numpy', 'numpy'))\n",
        "    # Create a dummy np to avoid NameError later\n",
        "    np = None\n",
        "\n",
        "# Now import cv2 (requires numpy to be imported first)\n",
        "try:\n",
        "    import cv2\n",
        "    print(\"  ‚úì cv2 (opencv-python)\")\n",
        "except (ImportError, AttributeError) as e:\n",
        "    # Handle both ImportError and AttributeError (_ARRAY_API issue)\n",
        "    if '_ARRAY_API' in str(e) or 'AttributeError' in str(type(e).__name__):\n",
        "        print(\"  ‚ö† cv2 import error (NumPy 2.x compatibility issue)\")\n",
        "        print(\"     Fixing by downgrading NumPy to < 2.0...\")\n",
        "        try:\n",
        "            import subprocess\n",
        "            import importlib\n",
        "            # Downgrade NumPy to < 2.0\n",
        "            subprocess.run([sys.executable, '-m', 'pip', 'install', 'numpy<2.0', '--force-reinstall', '--quiet'], \n",
        "                         check=False, timeout=120)\n",
        "            # Clear cached imports\n",
        "            if 'numpy' in sys.modules:\n",
        "                del sys.modules['numpy']\n",
        "            if 'cv2' in sys.modules:\n",
        "                del sys.modules['cv2']\n",
        "            # Re-import\n",
        "            import numpy as np\n",
        "            import cv2\n",
        "            print(f\"  ‚úì cv2 (fixed - NumPy {np.__version__})\")\n",
        "        except Exception as fix_error:\n",
        "            print(f\"  ‚úó cv2 - failed to fix: {fix_error}\")\n",
        "            print(\"     Try manually: pip install 'numpy<2.0' opencv-python --force-reinstall\")\n",
        "            failed_imports.append(('cv2', 'opencv-python'))\n",
        "    else:\n",
        "        print(\"  ‚úó cv2 - opencv-python not installed\")\n",
        "        failed_imports.append(('cv2', 'opencv-python'))\n",
        "\n",
        "# Import torch and torchvision\n",
        "try:\n",
        "    import torch\n",
        "    print(\"  ‚úì torch\")\n",
        "except ImportError:\n",
        "    print(\"  ‚úó torch - not installed\")\n",
        "    failed_imports.append(('torch', 'torch'))\n",
        "\n",
        "try:\n",
        "    import torchvision\n",
        "    print(\"  ‚úì torchvision\")\n",
        "except ImportError:\n",
        "    print(\"  ‚úó torchvision - not installed\")\n",
        "    failed_imports.append(('torchvision', 'torchvision'))\n",
        "\n",
        "try:\n",
        "    import matplotlib.pyplot as plt\n",
        "    print(\"  ‚úì matplotlib\")\n",
        "except ImportError:\n",
        "    print(\"  ‚úó matplotlib - not installed\")\n",
        "    failed_imports.append(('matplotlib', 'matplotlib'))\n",
        "\n",
        "try:\n",
        "    import seaborn as sns\n",
        "    print(\"  ‚úì seaborn\")\n",
        "except ImportError:\n",
        "    print(\"  ‚úó seaborn - not installed\")\n",
        "    failed_imports.append(('seaborn', 'seaborn'))\n",
        "\n",
        "try:\n",
        "    import pandas as pd\n",
        "    print(\"  ‚úì pandas\")\n",
        "except ImportError:\n",
        "    print(\"  ‚úó pandas - not installed\")\n",
        "    failed_imports.append(('pandas', 'pandas'))\n",
        "\n",
        "try:\n",
        "    import yaml\n",
        "    print(\"  ‚úì yaml (pyyaml)\")\n",
        "except ImportError:\n",
        "    print(\"  ‚úó yaml - pyyaml not installed\")\n",
        "    failed_imports.append(('yaml', 'pyyaml'))\n",
        "\n",
        "# Import standard library modules (should always work)\n",
        "import zipfile\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "try:\n",
        "    from tqdm import tqdm\n",
        "    print(\"  ‚úì tqdm\")\n",
        "except ImportError:\n",
        "    print(\"  ‚úó tqdm - not installed\")\n",
        "    failed_imports.append(('tqdm', 'tqdm'))\n",
        "\n",
        "# Import ultralytics (depends on torch and cv2)\n",
        "try:\n",
        "    from ultralytics import YOLO\n",
        "    from ultralytics.utils.metrics import ConfusionMatrix\n",
        "    print(\"  ‚úì ultralytics\")\n",
        "except (ImportError, AttributeError) as e:\n",
        "    error_msg = str(e)\n",
        "    if '_ARRAY_API' in error_msg or 'cv2' in error_msg.lower():\n",
        "        print(\"  ‚ö† ultralytics import error (likely cv2/numpy issue)\")\n",
        "        # If cv2 failed, ultralytics will also fail\n",
        "        cv2_failed = any(mod == 'cv2' for mod, _ in failed_imports)\n",
        "        if cv2_failed:\n",
        "            print(\"     This is expected - cv2 must be fixed first\")\n",
        "        else:\n",
        "            print(\"     Attempting to fix...\")\n",
        "            try:\n",
        "                import subprocess\n",
        "                import importlib\n",
        "                # Fix NumPy version and reinstall opencv-python\n",
        "                subprocess.run([sys.executable, '-m', 'pip', 'install', 'numpy<2.0', 'opencv-python', '--force-reinstall', '--quiet'], \n",
        "                             check=False, timeout=120)\n",
        "                # Clear any cached imports\n",
        "                if 'numpy' in sys.modules:\n",
        "                    del sys.modules['numpy']\n",
        "                if 'cv2' in sys.modules:\n",
        "                    del sys.modules['cv2']\n",
        "                if 'ultralytics' in sys.modules:\n",
        "                    del sys.modules['ultralytics']\n",
        "                # Re-import\n",
        "                import numpy as np\n",
        "                import cv2\n",
        "                from ultralytics import YOLO\n",
        "                from ultralytics.utils.metrics import ConfusionMatrix\n",
        "                print(\"  ‚úì ultralytics (fixed)\")\n",
        "            except Exception as fix_error:\n",
        "                print(f\"  ‚úó ultralytics - failed to fix: {fix_error}\")\n",
        "                print(\"     Try manually: pip install 'numpy<2.0' opencv-python ultralytics --force-reinstall\")\n",
        "                failed_imports.append(('ultralytics', 'ultralytics'))\n",
        "    else:\n",
        "        print(\"  ‚úó ultralytics - requires torch to be installed first\")\n",
        "        failed_imports.append(('ultralytics', 'ultralytics'))\n",
        "\n",
        "# Check for optional packages\n",
        "try:\n",
        "    import onnx\n",
        "    ONNX_AVAILABLE = True\n",
        "    print(\"  ‚úì ONNX (optional - for model export)\")\n",
        "except ImportError:\n",
        "    ONNX_AVAILABLE = False\n",
        "    print(\"  ‚ö† ONNX not available (optional - only needed for model export)\")\n",
        "\n",
        "# If critical imports failed, provide helpful error message\n",
        "if failed_imports:\n",
        "    print(f\"\\n‚úó Failed to import {len(failed_imports)} required package(s):\")\n",
        "    for module_name, package_name in failed_imports:\n",
        "        print(f\"   - {module_name} (install: {package_name})\")\n",
        "    print(f\"\\nüí° To fix this:\")\n",
        "    print(f\"   1. Re-run Cell 3 (installation cell) above\")\n",
        "    print(f\"   2. Or install manually: pip install {' '.join([pkg for _, pkg in failed_imports])}\")\n",
        "    print(f\"   3. Or install all: pip install -r requirements.txt\")\n",
        "    print(f\"\\n‚ö† Please install the missing packages before continuing!\")\n",
        "    raise ImportError(f\"Missing required packages: {', '.join([pkg for _, pkg in failed_imports])}\")\n",
        "\n",
        "# All imports successful\n",
        "print(f\"\\n‚úì All required packages imported successfully!\")\n",
        "print(f\"‚úì PyTorch version: {torch.__version__}\")\n",
        "print(f\"‚úì CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"‚úì GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"‚úì CUDA version: {torch.version.cuda}\")\n",
        "else:\n",
        "    print(\"‚ö† No GPU detected. Training will be slow on CPU.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "FIXING NUMPY/OPENCV-PYTHON COMPATIBILITY\n",
            "============================================================\n",
            "Current NumPy version: 1.26.4\n",
            "‚úì NumPy 1.26.4 is compatible (< 2.0)\n",
            "‚úì cv2 imports successfully - no fix needed\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Troubleshooting: Fix NumPy 2.x / opencv-python compatibility issues\n",
        "# Run this cell if you see _ARRAY_API errors or cv2 import failures\n",
        "# This fixes the NumPy 2.x incompatibility with opencv-python\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "import importlib\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"FIXING NUMPY/OPENCV-PYTHON COMPATIBILITY\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Check current NumPy version\n",
        "try:\n",
        "    import numpy as np\n",
        "    numpy_version = np.__version__\n",
        "    major_version = int(numpy_version.split('.')[0])\n",
        "    print(f\"Current NumPy version: {numpy_version}\")\n",
        "    \n",
        "    if major_version >= 2:\n",
        "        print(f\"\\n‚ö† PROBLEM: NumPy {numpy_version} is incompatible with opencv-python\")\n",
        "        print(\"  opencv-python was compiled for NumPy 1.x and cannot run with NumPy 2.x\")\n",
        "        print(\"\\n  Fixing by downgrading NumPy to < 2.0...\")\n",
        "        \n",
        "        # Downgrade NumPy\n",
        "        result = subprocess.run(\n",
        "            [sys.executable, '-m', 'pip', 'install', 'numpy<2.0', '--force-reinstall'],\n",
        "            capture_output=True,\n",
        "            text=True,\n",
        "            timeout=120\n",
        "        )\n",
        "        \n",
        "        if result.returncode == 0:\n",
        "            # Clear cached imports\n",
        "            if 'numpy' in sys.modules:\n",
        "                del sys.modules['numpy']\n",
        "            if 'cv2' in sys.modules:\n",
        "                del sys.modules['cv2']\n",
        "            if 'ultralytics' in sys.modules:\n",
        "                del sys.modules['ultralytics']\n",
        "            \n",
        "            # Re-import to verify\n",
        "            import numpy as np\n",
        "            print(f\"\\n‚úì SUCCESS: NumPy downgraded to {np.__version__}\")\n",
        "            print(\"\\n  Testing cv2 import...\")\n",
        "            try:\n",
        "                import cv2\n",
        "                print(\"  ‚úì cv2 imports successfully!\")\n",
        "                print(\"\\n‚úÖ FIXED! You can now re-run the import cell (Cell 4)\")\n",
        "            except Exception as e:\n",
        "                print(f\"  ‚úó cv2 still fails: {e}\")\n",
        "                print(\"\\n  Try manually: pip install 'numpy<2.0' opencv-python --force-reinstall\")\n",
        "        else:\n",
        "            print(f\"\\n‚úó Installation failed. Error:\")\n",
        "            print(result.stderr[:500] if result.stderr else \"Unknown error\")\n",
        "            print(\"\\n  Try manually: pip install 'numpy<2.0' --force-reinstall\")\n",
        "    else:\n",
        "        print(f\"‚úì NumPy {numpy_version} is compatible (< 2.0)\")\n",
        "        try:\n",
        "            import cv2\n",
        "            print(\"‚úì cv2 imports successfully - no fix needed\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö† cv2 import failed: {e}\")\n",
        "            print(\"  Try: pip install opencv-python --force-reinstall\")\n",
        "            \n",
        "except ImportError:\n",
        "    print(\"‚ö† NumPy not installed\")\n",
        "    print(\"  Installing NumPy < 2.0...\")\n",
        "    result = subprocess.run(\n",
        "        [sys.executable, '-m', 'pip', 'install', 'numpy<2.0'],\n",
        "        capture_output=True,\n",
        "        text=True,\n",
        "        timeout=120\n",
        "    )\n",
        "    if result.returncode == 0:\n",
        "        print(\"‚úì NumPy installed\")\n",
        "    else:\n",
        "        print(\"‚úó Installation failed\")\n",
        "\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "PATH CONFIGURATION\n",
            "============================================================\n",
            "Project Root: C:\\Users\\kensm\\farm-photo-outliner\n",
            "Dataset Dir:  C:\\Users\\kensm\\farm-photo-outliner\\sweetpotato_project\\dataset\n",
            "Data YAML:    C:\\Users\\kensm\\farm-photo-outliner\\sweetpotato_project\\dataset\\data.yaml\n",
            "Work Dir:     C:\\Users\\kensm\\farm-photo-outliner\\sweetpotato_project\n",
            "\n",
            "‚úì data.yaml found at: C:\\Users\\kensm\\farm-photo-outliner\\sweetpotato_project\\dataset\\data.yaml\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# ROBUST PATH HELPER - Works in both notebooks and scripts\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "# Get the root directory (notebook location or current working directory)\n",
        "def get_project_root():\n",
        "    \"\"\"Get the project root directory, works in notebooks and scripts\"\"\"\n",
        "    try:\n",
        "        # Try to get notebook file path (works in Jupyter/IPython)\n",
        "        import __main__\n",
        "        if hasattr(__main__, '__file__'):\n",
        "            return Path(__main__.__file__).resolve().parent\n",
        "    except:\n",
        "        pass\n",
        "    \n",
        "    # Fallback: use current working directory\n",
        "    return Path.cwd().resolve()\n",
        "\n",
        "# Set project root\n",
        "PROJECT_ROOT = get_project_root()\n",
        "\n",
        "# Define dataset paths\n",
        "DATASET_ROOT = PROJECT_ROOT / \"sweetpotato_project\" / \"dataset\"\n",
        "DATA_YAML_PATH = DATASET_ROOT / \"data.yaml\"\n",
        "WORK_DIR_PATH = PROJECT_ROOT / \"sweetpotato_project\"\n",
        "\n",
        "# Convert to absolute paths (strings for compatibility)\n",
        "DATASET_DIR = str(DATASET_ROOT.resolve())\n",
        "DATA_YAML = str(DATA_YAML_PATH.resolve())\n",
        "WORK_DIR = str(WORK_DIR_PATH.resolve())\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"PATH CONFIGURATION\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Project Root: {PROJECT_ROOT}\")\n",
        "print(f\"Dataset Dir:  {DATASET_DIR}\")\n",
        "print(f\"Data YAML:    {DATA_YAML}\")\n",
        "print(f\"Work Dir:     {WORK_DIR}\")\n",
        "\n",
        "# Verify data.yaml exists\n",
        "if not Path(DATA_YAML).exists():\n",
        "    print(f\"\\n‚ö† WARNING: data.yaml not found at {DATA_YAML}\")\n",
        "    print(f\"   It will be created in the dataset setup cell.\")\n",
        "else:\n",
        "    print(f\"\\n‚úì data.yaml found at: {DATA_YAML}\")\n",
        "\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì DATASET_DIR: C:\\Users\\kensm\\farm-photo-outliner\\sweetpotato_project\\dataset\n",
            "‚úì Found data.yaml at: C:\\Users\\kensm\\farm-photo-outliner\\sweetpotato_project\\dataset\\data.yaml\n",
            "‚úì Loaded data.yaml configuration\n",
            "  Classes: 3\n",
            "  Class names: ['Diseased', 'Healthy', 'Non-determined']\n"
          ]
        }
      ],
      "source": [
        "# SETUP: Find or create data.yaml before verification\n",
        "# This ensures data_yaml_path and data_config are defined\n",
        "\n",
        "import os\n",
        "import yaml\n",
        "from pathlib import Path\n",
        "\n",
        "# Find or determine DATASET_DIR\n",
        "if 'DATASET_DIR' not in globals() or ('DATASET_DIR' in globals() and not os.path.exists(DATASET_DIR)):\n",
        "    # Try to find dataset directory\n",
        "    possible_paths = [\n",
        "        './sweetpotato_project/dataset',\n",
        "        './dataset',\n",
        "        '../dataset',\n",
        "        os.path.join(os.getcwd(), 'dataset')\n",
        "    ]\n",
        "    \n",
        "    # Also check for extracted dataset paths\n",
        "    if 'DATASET_DIR_EXTRACTED' in globals() and DATASET_DIR_EXTRACTED and os.path.exists(DATASET_DIR_EXTRACTED):\n",
        "        possible_paths.insert(0, DATASET_DIR_EXTRACTED)\n",
        "    \n",
        "    DATASET_DIR = None\n",
        "    for path in possible_paths:\n",
        "        if os.path.exists(path) and os.path.isdir(path):\n",
        "            DATASET_DIR = os.path.abspath(path)\n",
        "            break\n",
        "    \n",
        "    if not DATASET_DIR:\n",
        "        # Create default dataset directory\n",
        "        DATASET_DIR = os.path.abspath('./sweetpotato_project/dataset')\n",
        "        os.makedirs(DATASET_DIR, exist_ok=True)\n",
        "        print(f\"‚ö† DATASET_DIR not found, created: {DATASET_DIR}\")\n",
        "    else:\n",
        "        print(f\"‚úì Using DATASET_DIR: {DATASET_DIR}\")\n",
        "else:\n",
        "    DATASET_DIR = os.path.abspath(DATASET_DIR)\n",
        "    print(f\"‚úì DATASET_DIR: {DATASET_DIR}\")\n",
        "\n",
        "# Find or create data.yaml\n",
        "DATA_YAML = \"data.yaml\"  # Configurable variable\n",
        "data_yaml_path = os.path.join(DATASET_DIR, DATA_YAML)\n",
        "\n",
        "if not os.path.exists(data_yaml_path):\n",
        "    # Search in subdirectories\n",
        "    print(f\"Searching for {DATA_YAML}...\")\n",
        "    found = False\n",
        "    for root, dirs, files in os.walk(DATASET_DIR):\n",
        "        if DATA_YAML in files:\n",
        "            data_yaml_path = os.path.join(root, DATA_YAML)\n",
        "            found = True\n",
        "            print(f\"‚úì Found {DATA_YAML} at: {data_yaml_path}\")\n",
        "            break\n",
        "    \n",
        "    if not found:\n",
        "        print(f\"‚ö† {DATA_YAML} not found. Creating template...\")\n",
        "        \n",
        "        # Create folder structure if missing\n",
        "        for folder in ['train/images', 'train/labels', 'valid/images', 'valid/labels', 'test/images', 'test/labels']:\n",
        "            folder_path = os.path.join(DATASET_DIR, folder)\n",
        "            os.makedirs(folder_path, exist_ok=True)\n",
        "        \n",
        "        # Create default data.yaml template\n",
        "        default_yaml = {\n",
        "            'path': DATASET_DIR,\n",
        "            'train': 'train/images',\n",
        "            'val': 'valid/images',\n",
        "            'test': 'test/images',\n",
        "            'nc': 3,  # Sweet potato classes\n",
        "            'names': ['Diseased', 'Healthy', 'Non-determined']\n",
        "        }\n",
        "        \n",
        "        with open(data_yaml_path, 'w') as f:\n",
        "            yaml.dump(default_yaml, f, default_flow_style=False, sort_keys=False)\n",
        "        \n",
        "        print(f\"‚úì Created {DATA_YAML} at: {data_yaml_path}\")\n",
        "        print(f\"‚úì Created dataset folder structure:\")\n",
        "        print(f\"   - train/images, train/labels\")\n",
        "        print(f\"   - valid/images, valid/labels\")\n",
        "        print(f\"   - test/images, test/labels\")\n",
        "else:\n",
        "    print(f\"‚úì Found {DATA_YAML} at: {data_yaml_path}\")\n",
        "\n",
        "# Load data.yaml\n",
        "try:\n",
        "    with open(data_yaml_path, 'r') as f:\n",
        "        data_config = yaml.safe_load(f)\n",
        "    print(f\"‚úì Loaded {DATA_YAML} configuration\")\n",
        "    print(f\"  Classes: {data_config.get('nc', 'N/A')}\")\n",
        "    print(f\"  Class names: {data_config.get('names', 'N/A')}\")\n",
        "except Exception as e:\n",
        "    print(f\"‚úó Error loading {DATA_YAML}: {e}\")\n",
        "    raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì Working directory: c:\\Users\\kensm\\farm-photo-outliner\\sweetpotato_project\n",
            "‚úì Running in LOCAL mode\n",
            "  Dataset zip: Sweetpotato_roots.v2i.yolov8 (1).zip\n",
            "  Extracted dataset: Not specified\n"
          ]
        }
      ],
      "source": [
        "# Configuration paths - ADAPT FOR YOUR SYSTEM\n",
        "if IS_COLAB:\n",
        "    DRIVE_PATH = '/content/drive/MyDrive'\n",
        "    DATASET_ZIP = 'Sweetpotato_roots.v2i.yolov8 (1).zip'  # Update this path\n",
        "    WORK_DIR = '/content/sweetpotato_project'\n",
        "    DATASET_DIR = f'{WORK_DIR}/dataset'\n",
        "else:\n",
        "    # LOCAL MODE: Update these paths for your system\n",
        "    # Option 1: Path to dataset zip file\n",
        "    DATASET_ZIP = 'Sweetpotato_roots.v2i.yolov8 (1).zip'  # Update this path or set to None\n",
        "    \n",
        "    # Option 2: Path to already extracted dataset (if you have it unzipped)\n",
        "    DATASET_DIR_EXTRACTED = None  # e.g., r'C:\\path\\to\\Sweetpotato_roots.v2i.yolov8'\n",
        "    \n",
        "    # Working directory (where outputs will be saved)\n",
        "    WORK_DIR = './sweetpotato_project'\n",
        "    DATASET_DIR = f'{WORK_DIR}/dataset'\n",
        "\n",
        "# Create working directory\n",
        "os.makedirs(WORK_DIR, exist_ok=True)\n",
        "if not IS_COLAB and DATASET_DIR_EXTRACTED is None:\n",
        "    os.makedirs(DATASET_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"‚úì Working directory: {os.path.abspath(WORK_DIR)}\")\n",
        "if not IS_COLAB:\n",
        "    print(f\"‚úì Running in LOCAL mode\")\n",
        "    print(f\"  Dataset zip: {DATASET_ZIP if DATASET_ZIP else 'Not specified'}\")\n",
        "    print(f\"  Extracted dataset: {DATASET_DIR_EXTRACTED if DATASET_DIR_EXTRACTED else 'Not specified'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ö† Dataset zip not found at specified path. Searching...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì Found dataset: c:\\Users\\kensm\\Downloads\\Sweetpotato_roots.v2i.yolov8 (1).zip\n",
            "‚úì Dataset structure prepared\n"
          ]
        }
      ],
      "source": [
        "# Locate and unzip dataset\n",
        "if IS_COLAB:\n",
        "    # Colab mode: search in Google Drive\n",
        "    zip_path = None\n",
        "    for root, dirs, files in os.walk(DRIVE_PATH):\n",
        "        if DATASET_ZIP in files:\n",
        "            zip_path = os.path.join(root, DATASET_ZIP)\n",
        "            break\n",
        "    \n",
        "    if zip_path is None:\n",
        "        raise FileNotFoundError(f\"Dataset zip file '{DATASET_ZIP}' not found in Google Drive. Please upload it.\")\n",
        "    \n",
        "    print(f\"‚úì Found dataset: {zip_path}\")\n",
        "    \n",
        "    # Unzip dataset\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(DATASET_DIR)\n",
        "        print(f\"‚úì Dataset extracted to {DATASET_DIR}\")\n",
        "    \n",
        "    # Find the actual dataset folder (may be nested)\n",
        "    dataset_folders = [f for f in os.listdir(DATASET_DIR) if os.path.isdir(os.path.join(DATASET_DIR, f))]\n",
        "    if len(dataset_folders) == 1:\n",
        "        actual_dataset = os.path.join(DATASET_DIR, dataset_folders[0])\n",
        "        # Move contents up one level if nested\n",
        "        for item in os.listdir(actual_dataset):\n",
        "            shutil.move(os.path.join(actual_dataset, item), os.path.join(DATASET_DIR, item))\n",
        "        os.rmdir(actual_dataset)\n",
        "    \n",
        "    print(f\"‚úì Dataset structure prepared\")\n",
        "else:\n",
        "    # LOCAL MODE: Handle dataset location\n",
        "    if DATASET_DIR_EXTRACTED and os.path.exists(DATASET_DIR_EXTRACTED):\n",
        "        # Use already extracted dataset\n",
        "        print(f\"‚úì Using extracted dataset from: {DATASET_DIR_EXTRACTED}\")\n",
        "        DATASET_DIR = DATASET_DIR_EXTRACTED\n",
        "    elif DATASET_ZIP and os.path.exists(DATASET_ZIP):\n",
        "        # Unzip from local path\n",
        "        print(f\"‚úì Found dataset zip: {DATASET_ZIP}\")\n",
        "        with zipfile.ZipFile(DATASET_ZIP, 'r') as zip_ref:\n",
        "            zip_ref.extractall(DATASET_DIR)\n",
        "        print(f\"‚úì Dataset extracted to {DATASET_DIR}\")\n",
        "        \n",
        "        # Handle nested folders\n",
        "        dataset_folders = [f for f in os.listdir(DATASET_DIR) if os.path.isdir(os.path.join(DATASET_DIR, f))]\n",
        "        if len(dataset_folders) == 1:\n",
        "            actual_dataset = os.path.join(DATASET_DIR, dataset_folders[0])\n",
        "            for item in os.listdir(actual_dataset):\n",
        "                shutil.move(os.path.join(actual_dataset, item), os.path.join(DATASET_DIR, item))\n",
        "            os.rmdir(actual_dataset)\n",
        "    else:\n",
        "        # Search in current directory and subdirectories\n",
        "        print(f\"‚ö† Dataset zip not found at specified path. Searching...\")\n",
        "        zip_found = False\n",
        "        search_paths = ['.', os.path.dirname(os.path.abspath('.'))]\n",
        "        for search_root in search_paths:\n",
        "            for root, dirs, files in os.walk(search_root):\n",
        "                if DATASET_ZIP and DATASET_ZIP in files:\n",
        "                    zip_path = os.path.join(root, DATASET_ZIP)\n",
        "                    print(f\"‚úì Found dataset: {zip_path}\")\n",
        "                    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "                        zip_ref.extractall(DATASET_DIR)\n",
        "                    zip_found = True\n",
        "                    break\n",
        "            if zip_found:\n",
        "                break\n",
        "        \n",
        "        if not zip_found:\n",
        "            raise FileNotFoundError(\n",
        "                f\"Dataset not found. Please either:\\n\"\n",
        "                f\"1. Place '{DATASET_ZIP}' in the current directory, or\\n\"\n",
        "                f\"2. Update DATASET_ZIP path in the configuration cell, or\\n\"\n",
        "                f\"3. Set DATASET_DIR_EXTRACTED to point to your extracted dataset\"\n",
        "            )\n",
        "    \n",
        "    print(f\"‚úì Dataset structure prepared\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "FIXING data.yaml FOR YOLOv8 COMPATIBILITY\n",
            "============================================================\n",
            "Data YAML: C:\\Users\\kensm\\farm-photo-outliner\\sweetpotato_project\\dataset\\data.yaml\n",
            "Dataset Dir: C:\\Users\\kensm\\farm-photo-outliner\\sweetpotato_project\\dataset\n",
            "‚úì Loaded existing data.yaml\n",
            "\n",
            "‚úì Fixed data.yaml with absolute path:\n",
            "  path: C:\\Users\\kensm\\farm-photo-outliner\\sweetpotato_project\\dataset\n",
            "  train: ../train/images\n",
            "  val: ../valid/images\n",
            "  test: ../test/images\n",
            "\n",
            "‚úì Verifying paths:\n",
            "  Train: C:\\Users\\kensm\\farm-photo-outliner\\sweetpotato_project\\dataset\\..\\train\\images - ‚úó MISSING\n",
            "  Val:   C:\\Users\\kensm\\farm-photo-outliner\\sweetpotato_project\\dataset\\..\\valid\\images - ‚úó MISSING\n",
            "  Test:  C:\\Users\\kensm\\farm-photo-outliner\\sweetpotato_project\\dataset\\..\\test\\images - ‚úó MISSING\n",
            "\n",
            "‚úì data_yaml_path (absolute): C:\\Users\\kensm\\farm-photo-outliner\\sweetpotato_project\\dataset\\data.yaml\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# FIX data.yaml - Ensure it has absolute 'path' field for YOLOv8\n",
        "# This is critical for YOLOv8 to find the dataset images\n",
        "\n",
        "from pathlib import Path\n",
        "import yaml\n",
        "\n",
        "# Get the data.yaml path (should be set in previous cells)\n",
        "if 'data_yaml_path' not in globals():\n",
        "    if 'DATA_YAML' in globals():\n",
        "        data_yaml_path = DATA_YAML\n",
        "    elif 'DATASET_DIR' in globals():\n",
        "        data_yaml_path = os.path.join(DATASET_DIR, 'data.yaml')\n",
        "    else:\n",
        "        # Use the robust path helper\n",
        "        data_yaml_path = str(PROJECT_ROOT / \"sweetpotato_project\" / \"dataset\" / \"data.yaml\")\n",
        "\n",
        "# Ensure absolute path\n",
        "data_yaml_path = str(Path(data_yaml_path).resolve())\n",
        "DATASET_DIR = str(Path(data_yaml_path).parent.resolve())\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"FIXING data.yaml FOR YOLOv8 COMPATIBILITY\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Data YAML: {data_yaml_path}\")\n",
        "print(f\"Dataset Dir: {DATASET_DIR}\")\n",
        "\n",
        "# Load existing data.yaml or create new one\n",
        "if Path(data_yaml_path).exists():\n",
        "    with open(data_yaml_path, 'r') as f:\n",
        "        data_config = yaml.safe_load(f) or {}\n",
        "    print(\"‚úì Loaded existing data.yaml\")\n",
        "else:\n",
        "    data_config = {}\n",
        "    print(\"‚ö† data.yaml not found, will create new one\")\n",
        "\n",
        "# CRITICAL: Set 'path' to absolute path (YOLOv8 requirement)\n",
        "data_config['path'] = str(Path(DATASET_DIR).resolve())\n",
        "\n",
        "# Ensure train/val/test paths are set (relative to 'path')\n",
        "if 'train' not in data_config:\n",
        "    data_config['train'] = 'train/images'\n",
        "if 'val' not in data_config:\n",
        "    data_config['val'] = 'valid/images'\n",
        "if 'test' not in data_config:\n",
        "    data_config['test'] = 'test/images'\n",
        "\n",
        "# Set classes if not set\n",
        "if 'nc' not in data_config:\n",
        "    data_config['nc'] = 3\n",
        "if 'names' not in data_config:\n",
        "    data_config['names'] = ['Diseased', 'Healthy', 'Non-determined']\n",
        "\n",
        "# Write the fixed data.yaml\n",
        "with open(data_yaml_path, 'w') as f:\n",
        "    yaml.dump(data_config, f, default_flow_style=False, sort_keys=False)\n",
        "\n",
        "print(f\"\\n‚úì Fixed data.yaml with absolute path:\")\n",
        "print(f\"  path: {data_config['path']}\")\n",
        "print(f\"  train: {data_config['train']}\")\n",
        "print(f\"  val: {data_config['val']}\")\n",
        "print(f\"  test: {data_config['test']}\")\n",
        "\n",
        "# Verify paths exist\n",
        "train_path = Path(data_config['path']) / data_config['train']\n",
        "val_path = Path(data_config['path']) / data_config['val']\n",
        "test_path = Path(data_config['path']) / data_config['test']\n",
        "\n",
        "print(f\"\\n‚úì Verifying paths:\")\n",
        "print(f\"  Train: {train_path} - {'‚úì EXISTS' if train_path.exists() else '‚úó MISSING'}\")\n",
        "print(f\"  Val:   {val_path} - {'‚úì EXISTS' if val_path.exists() else '‚úó MISSING'}\")\n",
        "print(f\"  Test:  {test_path} - {'‚úì EXISTS' if test_path.exists() else '‚úó MISSING'}\")\n",
        "\n",
        "# Store the absolute path for use in training\n",
        "data_yaml_path_absolute = str(Path(data_yaml_path).resolve())\n",
        "print(f\"\\n‚úì data_yaml_path (absolute): {data_yaml_path_absolute}\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "VERIFYING DATA PATHS FOR YOLOv8 TRAINING\n",
            "============================================================\n",
            "\n",
            "üìÅ Data paths from data.yaml (resolved):\n",
            "  Train: C:\\Users\\kensm\\farm-photo-outliner\\sweetpotato_project\\train\\images\n",
            "  Val:   C:\\Users\\kensm\\farm-photo-outliner\\sweetpotato_project\\valid\\images\n",
            "  Test:  C:\\Users\\kensm\\farm-photo-outliner\\sweetpotato_project\\test\\images\n",
            "\n",
            "‚úì Verification Results:\n",
            "  Train: ‚úó 0 images - Path does not exist: C:\\Users\\kensm\\farm-photo-outliner\\sweetpotato_project\\train\\images\n",
            "  Val:   ‚úó 0 images - Path does not exist: C:\\Users\\kensm\\farm-photo-outliner\\sweetpotato_project\\valid\\images\n",
            "  Test:  ‚úó 0 images - Path does not exist: C:\\Users\\kensm\\farm-photo-outliner\\sweetpotato_project\\test\\images\n",
            "\n",
            "‚ö† WARNING: Some paths are incorrect!\n",
            "   Fixing data.yaml paths...\n",
            "   ‚úì Updated data.yaml with corrected paths\n",
            "   New paths:\n",
            "     Train: ../train/images\n",
            "     Val:   ../valid/images\n",
            "     Test:  ../test/images\n",
            "\n",
            "============================================================\n",
            "FINAL VERIFICATION - Model will use:\n",
            "============================================================\n",
            "  ‚úó TRAIN: NOT FOUND or EMPTY\n",
            "  ‚úó VAL:   NOT FOUND or EMPTY\n",
            "  ‚úó TEST:  NOT FOUND or EMPTY\n",
            "\n",
            "‚ö† WARNING: Some splits are missing or empty!\n",
            "   Please check your dataset structure.\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# VERIFY DATA PATHS - Ensure model will use train, val, and test splits\n",
        "print(\"=\"*60)\n",
        "print(\"VERIFYING DATA PATHS FOR YOLOv8 TRAINING\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Resolve paths from data.yaml (YOLOv8 resolves paths relative to data.yaml location)\n",
        "data_yaml_dir = os.path.dirname(os.path.abspath(data_yaml_path))\n",
        "\n",
        "def resolve_path(path_str, base_dir):\n",
        "    \"\"\"Resolve relative or absolute path\"\"\"\n",
        "    if os.path.isabs(path_str):\n",
        "        return path_str\n",
        "    # Resolve relative to data.yaml directory\n",
        "    resolved = os.path.normpath(os.path.join(base_dir, path_str))\n",
        "    return resolved\n",
        "\n",
        "# Get paths from config\n",
        "train_path = data_config.get('train', '')\n",
        "val_path = data_config.get('val', '')\n",
        "test_path = data_config.get('test', '')\n",
        "\n",
        "# Resolve to absolute paths\n",
        "train_abs = resolve_path(train_path, data_yaml_dir)\n",
        "val_abs = resolve_path(val_path, data_yaml_dir)\n",
        "test_abs = resolve_path(test_path, data_yaml_dir)\n",
        "\n",
        "print(f\"\\nüìÅ Data paths from data.yaml (resolved):\")\n",
        "print(f\"  Train: {train_abs}\")\n",
        "print(f\"  Val:   {val_abs}\")\n",
        "print(f\"  Test:  {test_abs}\")\n",
        "\n",
        "# Verify each path exists and count images\n",
        "def verify_split(split_name, path):\n",
        "    \"\"\"Verify a split path exists and count images\"\"\"\n",
        "    if not os.path.exists(path):\n",
        "        return False, 0, f\"Path does not exist: {path}\"\n",
        "    \n",
        "    # Count images\n",
        "    image_files = []\n",
        "    if os.path.isdir(path):\n",
        "        # Direct image directory\n",
        "        image_files = [f for f in os.listdir(path) \n",
        "                      if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]\n",
        "    else:\n",
        "        # Path might point to a file (shouldn't happen)\n",
        "        return False, 0, f\"Path is not a directory: {path}\"\n",
        "    \n",
        "    return True, len(image_files), None\n",
        "\n",
        "# Verify all splits\n",
        "train_exists, train_count, train_error = verify_split('Train', train_abs)\n",
        "val_exists, val_count, val_error = verify_split('Val', val_abs)\n",
        "test_exists, test_count, test_error = verify_split('Test', test_abs)\n",
        "\n",
        "print(f\"\\n‚úì Verification Results:\")\n",
        "print(f\"  Train: {'‚úì' if train_exists else '‚úó'} {train_count} images\" + (f\" - {train_error}\" if train_error else \"\"))\n",
        "print(f\"  Val:   {'‚úì' if val_exists else '‚úó'} {val_count} images\" + (f\" - {val_error}\" if val_error else \"\"))\n",
        "print(f\"  Test:  {'‚úì' if test_exists else '‚úó'} {test_count} images\" + (f\" - {test_error}\" if test_error else \"\"))\n",
        "\n",
        "# Check if paths need fixing\n",
        "needs_fix = False\n",
        "if not train_exists or not val_exists or not test_exists:\n",
        "    needs_fix = True\n",
        "    print(f\"\\n‚ö† WARNING: Some paths are incorrect!\")\n",
        "    print(f\"   Fixing data.yaml paths...\")\n",
        "    \n",
        "    # Fix paths - use absolute paths or correct relative paths\n",
        "    # YOLOv8 works best with paths relative to data.yaml location\n",
        "    data_yaml_dir_abs = os.path.abspath(data_yaml_dir)\n",
        "    \n",
        "    # Try to find correct paths\n",
        "    # Standard YOLOv8 structure: dataset/train/images, dataset/valid/images, dataset/test/images\n",
        "    dataset_root = os.path.dirname(data_yaml_dir_abs) if 'data.yaml' in os.listdir(data_yaml_dir_abs) else data_yaml_dir_abs\n",
        "    \n",
        "    # Check for standard structure\n",
        "    train_standard = os.path.join(dataset_root, 'train', 'images')\n",
        "    val_standard = os.path.join(dataset_root, 'valid', 'images')\n",
        "    test_standard = os.path.join(dataset_root, 'test', 'images')\n",
        "    \n",
        "    # Use standard paths if they exist, otherwise try current paths\n",
        "    if os.path.exists(train_standard):\n",
        "        train_path_fixed = 'train/images'\n",
        "    elif os.path.exists(os.path.join(dataset_root, 'train')):\n",
        "        train_path_fixed = 'train/images' if os.path.exists(train_standard) else 'train'\n",
        "    else:\n",
        "        train_path_fixed = train_path  # Keep original\n",
        "    \n",
        "    if os.path.exists(val_standard):\n",
        "        val_path_fixed = 'valid/images'\n",
        "    elif os.path.exists(os.path.join(dataset_root, 'valid')):\n",
        "        val_path_fixed = 'valid/images' if os.path.exists(val_standard) else 'valid'\n",
        "    else:\n",
        "        val_path_fixed = val_path  # Keep original\n",
        "    \n",
        "    if os.path.exists(test_standard):\n",
        "        test_path_fixed = 'test/images'\n",
        "    elif os.path.exists(os.path.join(dataset_root, 'test')):\n",
        "        test_path_fixed = 'test/images' if os.path.exists(test_standard) else 'test'\n",
        "    else:\n",
        "        test_path_fixed = test_path  # Keep original\n",
        "    \n",
        "    # Update data.yaml\n",
        "    data_config['train'] = train_path_fixed\n",
        "    data_config['val'] = val_path_fixed\n",
        "    data_config['test'] = test_path_fixed\n",
        "    \n",
        "    # Also add 'path' field if missing (YOLOv8 uses this as base path)\n",
        "    if 'path' not in data_config:\n",
        "        data_config['path'] = dataset_root\n",
        "    \n",
        "    # Write updated config\n",
        "    with open(data_yaml_path, 'w') as f:\n",
        "        yaml.dump(data_config, f, default_flow_style=False, sort_keys=False)\n",
        "    \n",
        "    print(f\"   ‚úì Updated data.yaml with corrected paths\")\n",
        "    print(f\"   New paths:\")\n",
        "    print(f\"     Train: {data_config['train']}\")\n",
        "    print(f\"     Val:   {data_config['val']}\")\n",
        "    print(f\"     Test:  {data_config['test']}\")\n",
        "    \n",
        "    # Reload to verify\n",
        "    with open(data_yaml_path, 'r') as f:\n",
        "        data_config = yaml.safe_load(f)\n",
        "    \n",
        "    train_abs = resolve_path(data_config['train'], data_yaml_dir)\n",
        "    val_abs = resolve_path(data_config['val'], data_yaml_dir)\n",
        "    test_abs = resolve_path(data_config['test'], data_yaml_dir)\n",
        "    \n",
        "    train_exists, train_count, _ = verify_split('Train', train_abs)\n",
        "    val_exists, val_count, _ = verify_split('Val', val_abs)\n",
        "    test_exists, test_count, _ = verify_split('Test', test_abs)\n",
        "\n",
        "# Final summary\n",
        "print(f\"\\n\" + \"=\"*60)\n",
        "print(\"FINAL VERIFICATION - Model will use:\")\n",
        "print(\"=\"*60)\n",
        "if train_exists and train_count > 0:\n",
        "    print(f\"  ‚úì TRAIN: {train_count} images - {train_abs}\")\n",
        "else:\n",
        "    print(f\"  ‚úó TRAIN: NOT FOUND or EMPTY\")\n",
        "    \n",
        "if val_exists and val_count > 0:\n",
        "    print(f\"  ‚úì VAL:   {val_count} images - {val_abs}\")\n",
        "else:\n",
        "    print(f\"  ‚úó VAL:   NOT FOUND or EMPTY\")\n",
        "    \n",
        "if test_exists and test_count > 0:\n",
        "    print(f\"  ‚úì TEST:  {test_count} images - {test_abs}\")\n",
        "else:\n",
        "    print(f\"  ‚úó TEST:  NOT FOUND or EMPTY\")\n",
        "\n",
        "if train_exists and val_exists and test_exists and train_count > 0 and val_count > 0 and test_count > 0:\n",
        "    print(f\"\\n‚úÖ SUCCESS: All three splits are configured correctly!\")\n",
        "    print(f\"   The model will use:\")\n",
        "    print(f\"   - {train_count} training images\")\n",
        "    print(f\"   - {val_count} validation images\") \n",
        "    print(f\"   - {test_count} test images\")\n",
        "    print(f\"\\n   You can proceed with training!\")\n",
        "else:\n",
        "    print(f\"\\n‚ö† WARNING: Some splits are missing or empty!\")\n",
        "    print(f\"   Please check your dataset structure.\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì Found train/ folder\n",
            "‚úì Found valid/ folder\n",
            "‚úì Found test/ folder\n",
            "‚úì Found data.yaml: C:\\Users\\kensm\\farm-photo-outliner\\sweetpotato_project\\dataset\\data.yaml\n",
            "\n",
            "Dataset Configuration:\n",
            "  Classes: 3\n",
            "  Class names: ['Diseased', 'Healthy', 'Non-determined']\n",
            "  Train: ../train/images\n",
            "  Val: ../valid/images\n",
            "  Test: ../test/images\n"
          ]
        }
      ],
      "source": [
        "# Verify dataset structure\n",
        "required_folders = ['train', 'valid', 'test']\n",
        "missing_folders = []\n",
        "\n",
        "for folder in required_folders:\n",
        "    folder_path = os.path.join(DATASET_DIR, folder)\n",
        "    if not os.path.exists(folder_path):\n",
        "        missing_folders.append(folder)\n",
        "    else:\n",
        "        print(f\"‚úì Found {folder}/ folder\")\n",
        "\n",
        "if missing_folders:\n",
        "    raise FileNotFoundError(f\"Missing required folders: {missing_folders}\")\n",
        "\n",
        "# Check for data.yaml\n",
        "data_yaml_path = os.path.join(DATASET_DIR, 'data.yaml')\n",
        "if not os.path.exists(data_yaml_path):\n",
        "    # Search in subdirectories\n",
        "    for root, dirs, files in os.walk(DATASET_DIR):\n",
        "        if 'data.yaml' in files:\n",
        "            data_yaml_path = os.path.join(root, 'data.yaml')\n",
        "            break\n",
        "    if not os.path.exists(data_yaml_path):\n",
        "        raise FileNotFoundError(\"data.yaml not found. Creating default...\")\n",
        "        # Create default data.yaml\n",
        "        default_yaml = {\n",
        "            'path': DATASET_DIR,\n",
        "            'train': 'train/images',\n",
        "            'val': 'valid/images',\n",
        "            'test': 'test/images',\n",
        "            'nc': 2,\n",
        "            'names': ['sweetpotato_root', 'background']\n",
        "        }\n",
        "        with open(data_yaml_path, 'w') as f:\n",
        "            yaml.dump(default_yaml, f)\n",
        "\n",
        "print(f\"‚úì Found data.yaml: {data_yaml_path}\")\n",
        "\n",
        "# Load and display data.yaml\n",
        "with open(data_yaml_path, 'r') as f:\n",
        "    data_config = yaml.safe_load(f)\n",
        "\n",
        "print(\"\\nDataset Configuration:\")\n",
        "print(f\"  Classes: {data_config.get('nc', 'N/A')}\")\n",
        "print(f\"  Class names: {data_config.get('names', 'N/A')}\")\n",
        "print(f\"  Train: {data_config.get('train', 'N/A')}\")\n",
        "print(f\"  Val: {data_config.get('val', 'N/A')}\")\n",
        "print(f\"  Test: {data_config.get('test', 'N/A')}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validating dataset splits...\n",
            "\n",
            "TRAIN:\n",
            "  Images: 57\n",
            "  Labels: 57\n",
            "  ‚ö† Missing images for 57 labels\n",
            "\n",
            "VALID:\n",
            "  Images: 5\n",
            "  Labels: 5\n",
            "  ‚ö† Missing images for 5 labels\n",
            "\n",
            "TEST:\n",
            "  Images: 3\n",
            "  Labels: 3\n",
            "  ‚ö† Missing images for 3 labels\n",
            "\n",
            "‚úì Dataset validation complete\n"
          ]
        }
      ],
      "source": [
        "# Validate image-annotation pairs\n",
        "def validate_dataset(split='train'):\n",
        "    split_path = os.path.join(DATASET_DIR, split)\n",
        "    images_dir = os.path.join(split_path, 'images')\n",
        "    labels_dir = os.path.join(split_path, 'labels')\n",
        "    \n",
        "    if not os.path.exists(images_dir):\n",
        "        images_dir = split_path\n",
        "        labels_dir = split_path\n",
        "    \n",
        "    if not os.path.exists(labels_dir):\n",
        "        print(f\"‚ö† Warning: {split}/labels not found, assuming labels are in {split}/\")\n",
        "        labels_dir = split_path\n",
        "    \n",
        "    image_files = [f for f in os.listdir(images_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "    label_files = [f for f in os.listdir(labels_dir) if f.endswith('.txt')]\n",
        "    \n",
        "    missing_labels = []\n",
        "    missing_images = []\n",
        "    \n",
        "    for img_file in image_files:\n",
        "        label_file = os.path.splitext(img_file)[0] + '.txt'\n",
        "        label_path = os.path.join(labels_dir, label_file)\n",
        "        if not os.path.exists(label_path):\n",
        "            missing_labels.append(img_file)\n",
        "    \n",
        "    for label_file in label_files:\n",
        "        img_file = os.path.splitext(label_file)[0] + '.jpg'\n",
        "        if not img_file in [f.lower() for f in image_files]:\n",
        "            # Try other extensions\n",
        "            found = False\n",
        "            for ext in ['.png', '.jpeg', '.JPG', '.PNG']:\n",
        "                if os.path.splitext(label_file)[0] + ext in image_files:\n",
        "                    found = True\n",
        "                    break\n",
        "            if not found:\n",
        "                missing_images.append(label_file)\n",
        "    \n",
        "    return len(image_files), len(label_files), missing_labels, missing_images\n",
        "\n",
        "# Validate all splits\n",
        "print(\"Validating dataset splits...\")\n",
        "for split in ['train', 'valid', 'test']:\n",
        "    img_count, label_count, missing_lbls, missing_imgs = validate_dataset(split)\n",
        "    print(f\"\\n{split.upper()}:\")\n",
        "    print(f\"  Images: {img_count}\")\n",
        "    print(f\"  Labels: {label_count}\")\n",
        "    if missing_lbls:\n",
        "        print(f\"  ‚ö† Missing labels for {len(missing_lbls)} images\")\n",
        "    if missing_imgs:\n",
        "        print(f\"  ‚ö† Missing images for {len(missing_imgs)} labels\")\n",
        "    if not missing_lbls and not missing_imgs:\n",
        "        print(f\"  ‚úì All pairs validated\")\n",
        "\n",
        "print(\"\\n‚úì Dataset validation complete\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "GPU DIAGNOSTICS\n",
            "======================================================================\n",
            "\n",
            "PyTorch: 2.6.0+cu124\n",
            "‚úì PyTorch has CUDA support\n",
            "\n",
            "CUDA available: True\n",
            "‚úì CUDA version: 12.4\n",
            "‚úì GPU count: 1\n",
            "\n",
            "‚úì GPU 0: NVIDIA GeForce RTX 4070 Laptop GPU\n",
            "  Memory: 8.0 GB\n",
            "  Compute Capability: 8.9\n",
            "  ‚úÖ RTX 4070 detected!\n",
            "\n",
            "‚úì Device Selected: cuda\n",
            "‚úì Training will use: GPU 0 (NVIDIA GeForce RTX 4070 Laptop GPU)\n",
            "======================================================================\n",
            "Device: cuda\n",
            "TRAINING_DEVICE: 0\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# GPU DIAGNOSTICS - Enhanced for RTX 4070\n",
        "# Bulletproof GPU detection and verification\n",
        "\n",
        "import torch\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"GPU DIAGNOSTICS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Check PyTorch version\n",
        "print(f\"\\nPyTorch: {torch.__version__}\")\n",
        "if '+cpu' in torch.__version__:\n",
        "    print(\"üö® PROBLEM: CPU-only PyTorch installed!\")\n",
        "    print(\"   This is why GPU is not being used.\")\n",
        "else:\n",
        "    print(\"‚úì PyTorch has CUDA support\")\n",
        "\n",
        "# Check CUDA availability\n",
        "cuda_available = torch.cuda.is_available()\n",
        "print(f\"\\nCUDA available: {cuda_available}\")\n",
        "\n",
        "if cuda_available:\n",
        "    print(f\"‚úì CUDA version: {torch.version.cuda}\")\n",
        "    print(f\"‚úì GPU count: {torch.cuda.device_count()}\")\n",
        "    \n",
        "    for i in range(torch.cuda.device_count()):\n",
        "        gpu_name = torch.cuda.get_device_name(i)\n",
        "        props = torch.cuda.get_device_properties(i)\n",
        "        gpu_memory_gb = props.total_memory / 1024**3\n",
        "        \n",
        "        print(f\"\\n‚úì GPU {i}: {gpu_name}\")\n",
        "        print(f\"  Memory: {gpu_memory_gb:.1f} GB\")\n",
        "        print(f\"  Compute Capability: {props.major}.{props.minor}\")\n",
        "        \n",
        "        # For RTX 4070, verify it's detected\n",
        "        if '4070' in gpu_name or 'RTX' in gpu_name:\n",
        "            print(f\"  ‚úÖ RTX 4070 detected!\")\n",
        "    \n",
        "    # Clear cache\n",
        "    torch.cuda.empty_cache()\n",
        "    \n",
        "    # Set device variables\n",
        "    device = torch.device(\"cuda\")\n",
        "    TRAINING_DEVICE = '0'  # Use first GPU (RTX 4070)\n",
        "    \n",
        "    print(f\"\\n‚úì Device Selected: {device}\")\n",
        "    print(f\"‚úì Training will use: GPU 0 ({torch.cuda.get_device_name(0)})\")\n",
        "else:\n",
        "    print(\"\\nüö® GPU NOT AVAILABLE - check drivers/CUDA toolkit\")\n",
        "    \n",
        "    # Check NVIDIA drivers\n",
        "    print(\"\\nChecking NVIDIA drivers...\")\n",
        "    try:\n",
        "        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True, timeout=5)\n",
        "        if result.returncode == 0:\n",
        "            print(\"‚úì NVIDIA drivers installed\")\n",
        "            print(\"‚ö† But PyTorch can't see GPU - need CUDA-enabled PyTorch\")\n",
        "            print(\"\\nSOLUTION: Install CUDA-enabled PyTorch\")\n",
        "            print(\"Run these commands in terminal:\")\n",
        "            print(\"=\"*60)\n",
        "            print(\"pip uninstall -y torch torchvision torchaudio ultralytics\")\n",
        "            print(\"pip install --index-url https://download.pytorch.org/whl/cu124 torch torchvision torchaudio --upgrade\")\n",
        "            print(\"pip install ultralytics --upgrade\")\n",
        "            print(\"=\"*60)\n",
        "        else:\n",
        "            print(\"‚úó nvidia-smi not found\")\n",
        "    except:\n",
        "        print(\"‚ö† Could not check NVIDIA drivers\")\n",
        "    \n",
        "    # Fallback to CPU\n",
        "    device = torch.device(\"cpu\")\n",
        "    TRAINING_DEVICE = 'cpu'\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(f\"Device: {device}\")\n",
        "print(f\"TRAINING_DEVICE: {TRAINING_DEVICE}\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "AUTO-FIX: GPU PyTorch Installation\n",
            "======================================================================\n",
            "‚úì CUDA is already available!\n",
            "‚úì GPU: NVIDIA GeForce RTX 4070 Laptop GPU\n",
            "‚úì No installation needed\n"
          ]
        }
      ],
      "source": [
        "# AUTO-FIX: Install GPU PyTorch if CUDA not available\n",
        "# This cell will automatically install CUDA-enabled PyTorch if GPU is not detected\n",
        "\n",
        "import torch\n",
        "import subprocess\n",
        "import sys\n",
        "import importlib\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"AUTO-FIX: GPU PyTorch Installation\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "if not torch.cuda.is_available():\n",
        "    print(\"\\nüö® CUDA not available - installing GPU PyTorch...\")\n",
        "    print(\"This will uninstall CPU PyTorch and install CUDA 12.4 version\")\n",
        "    print(\"(Compatible with RTX 4070 and RTX 40-series GPUs)\\n\")\n",
        "    \n",
        "    try:\n",
        "        # Step 1: Uninstall CPU PyTorch\n",
        "        print(\"Step 1: Uninstalling CPU PyTorch...\")\n",
        "        subprocess.check_call([\n",
        "            sys.executable, \"-m\", \"pip\", \"uninstall\", \"-y\", \n",
        "            \"torch\", \"torchvision\", \"torchaudio\", \"ultralytics\"\n",
        "        ], timeout=120)\n",
        "        print(\"‚úì Uninstalled CPU PyTorch\")\n",
        "        \n",
        "        # Step 2: Install CUDA 12.4 PyTorch (for RTX 4070)\n",
        "        print(\"\\nStep 2: Installing CUDA 12.4 PyTorch...\")\n",
        "        subprocess.check_call([\n",
        "            sys.executable, \"-m\", \"pip\", \"install\", \n",
        "            \"--index-url\", \"https://download.pytorch.org/whl/cu124\",\n",
        "            \"torch\", \"torchvision\", \"torchaudio\", \"--upgrade\"\n",
        "        ], timeout=300)\n",
        "        print(\"‚úì Installed CUDA PyTorch\")\n",
        "        \n",
        "        # Step 3: Reinstall ultralytics\n",
        "        print(\"\\nStep 3: Reinstalling ultralytics...\")\n",
        "        subprocess.check_call([\n",
        "            sys.executable, \"-m\", \"pip\", \"install\", \"ultralytics\", \"--upgrade\"\n",
        "        ], timeout=120)\n",
        "        print(\"‚úì Reinstalled ultralytics\")\n",
        "        \n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"‚úÖ INSTALLATION COMPLETE!\")\n",
        "        print(\"=\"*70)\n",
        "        print(\"\\n‚ö† IMPORTANT: Restart kernel now!\")\n",
        "        print(\"   Kernel ‚Üí Restart (or Ctrl+Shift+P ‚Üí 'Restart')\")\n",
        "        print(\"\\n   Then re-run Cell 16 (GPU Diagnostics) to verify GPU is detected\")\n",
        "        print(\"=\"*70)\n",
        "        \n",
        "    except subprocess.TimeoutExpired:\n",
        "        print(\"‚ö† Installation timed out - try running commands manually in terminal\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö† Installation error: {e}\")\n",
        "        print(\"\\nPlease run these commands manually in terminal:\")\n",
        "        print(\"=\"*60)\n",
        "        print(\"pip uninstall -y torch torchvision torchaudio ultralytics\")\n",
        "        print(\"pip install --index-url https://download.pytorch.org/whl/cu124 torch torchvision torchaudio --upgrade\")\n",
        "        print(\"pip install ultralytics --upgrade\")\n",
        "        print(\"=\"*60)\n",
        "else:\n",
        "    print(\"‚úì CUDA is already available!\")\n",
        "    print(f\"‚úì GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(\"‚úì No installation needed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì Loaded config from ./config.yaml\n",
            "\n",
            "Training Configuration:\n",
            "  model: yolov8m-seg.pt\n",
            "  epochs: 100\n",
            "  imgsz: 640\n",
            "  batch: 16\n",
            "  optimizer: AdamW\n",
            "  lr0: 0.01\n",
            "  lrf: 0.01\n",
            "  momentum: 0.937\n",
            "  weight_decay: 0.0005\n",
            "  warmup_epochs: 3.0\n",
            "  warmup_momentum: 0.8\n",
            "  warmup_bias_lr: 0.1\n",
            "  box: 7.5\n",
            "  cls: 0.5\n",
            "  dfl: 1.5\n",
            "  pose: 12.0\n",
            "  kobj: 2.0\n",
            "  label_smoothing: 0.0\n",
            "  nbs: 64\n",
            "  hsv_h: 0.015\n",
            "  hsv_s: 0.7\n",
            "  hsv_v: 0.4\n",
            "  degrees: 0.0\n",
            "  translate: 0.1\n",
            "  scale: 0.5\n",
            "  shear: 0.0\n",
            "  perspective: 0.0\n",
            "  flipud: 0.0\n",
            "  fliplr: 0.5\n",
            "  mosaic: 1.0\n",
            "  mixup: 0.15\n",
            "  copy_paste: 0.0\n",
            "  auto_augment: randaugment\n",
            "  erasing: 0.4\n",
            "  crop_fraction: 1.0\n",
            "  save_period: 10\n",
            "  patience: 50\n",
            "  seed: 42\n",
            "  deterministic: True\n",
            "  amp: True\n",
            "  overlap_mask: True\n",
            "  mask_ratio: 4\n",
            "  pretrained: True\n",
            "  freeze: None\n",
            "  val: True\n",
            "  plots: True\n"
          ]
        }
      ],
      "source": [
        "# Load training configuration\n",
        "if IS_COLAB:\n",
        "    config_path = '/content/config.yaml'  # Will be uploaded or created\n",
        "else:\n",
        "    config_path = './config.yaml'  # Local config file\n",
        "\n",
        "# Default configuration (yolov8m-seg = medium; more capacity than n for finer masks)\n",
        "default_config = {\n",
        "    'model': 'yolov8m-seg.pt',  # Options: yolov8n-seg.pt, yolov8s-seg.pt, yolov8m-seg.pt, yolov8l-seg.pt, yolov8x-seg.pt\n",
        "    'epochs': 100,\n",
        "    'imgsz': 640,\n",
        "    'batch': 16,\n",
        "    'optimizer': 'AdamW',\n",
        "    'lr0': 0.01,\n",
        "    'lrf': 0.01,\n",
        "    'momentum': 0.937,\n",
        "    'weight_decay': 0.0005,\n",
        "    'warmup_epochs': 3.0,\n",
        "    'warmup_momentum': 0.8,\n",
        "    'warmup_bias_lr': 0.1,\n",
        "    'box': 7.5,\n",
        "    'cls': 0.5,\n",
        "    'dfl': 1.5,\n",
        "    'pose': 12.0,\n",
        "    'kobj': 2.0,\n",
        "    'label_smoothing': 0.0,\n",
        "    'nbs': 64,\n",
        "    'hsv_h': 0.015,\n",
        "    'hsv_s': 0.7,\n",
        "    'hsv_v': 0.4,\n",
        "    'degrees': 0.0,\n",
        "    'translate': 0.1,\n",
        "    'scale': 0.5,\n",
        "    'shear': 0.0,\n",
        "    'perspective': 0.0,\n",
        "    'flipud': 0.0,\n",
        "    'fliplr': 0.5,\n",
        "    'mosaic': 1.0,\n",
        "    'mixup': 0.15,\n",
        "    'copy_paste': 0.0,\n",
        "    'auto_augment': 'randaugment',\n",
        "    'erasing': 0.4,\n",
        "    'crop_fraction': 1.0\n",
        "}\n",
        "\n",
        "if os.path.exists(config_path):\n",
        "    with open(config_path, 'r') as f:\n",
        "        user_config = yaml.safe_load(f)\n",
        "    default_config.update(user_config)\n",
        "    print(f\"‚úì Loaded config from {config_path}\")\n",
        "else:\n",
        "    print(f\"‚ö† Config file not found, using defaults\")\n",
        "\n",
        "print(\"\\nTraining Configuration:\")\n",
        "for key, value in default_config.items():\n",
        "    print(f\"  {key}: {value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì Applied PyTorch 2.6+ compatibility fix for YOLOv8 model loading\n"
          ]
        },
        {
          "ename": "RecursionError",
          "evalue": "maximum recursion depth exceeded",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[48], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Initialize YOLOv8 segmentation model (m-seg = medium; more parameters/channels than n for finer masks)\u001b[39;00m\n\u001b[0;32m     29\u001b[0m model_name \u001b[38;5;241m=\u001b[39m default_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 30\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(model_name)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úì Loaded model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úì Model parameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msum\u001b[39m(p\u001b[38;5;241m.\u001b[39mnumel()\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mp\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mmodel\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mparameters())\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\kensm\\anaconda3\\Lib\\site-packages\\ultralytics\\models\\yolo\\model.py:76\u001b[0m, in \u001b[0;36mYOLO.__init__\u001b[1;34m(self, model, task, verbose)\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m \u001b[38;5;241m=\u001b[39m new_instance\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;66;03m# Continue with default YOLO initialization\u001b[39;00m\n\u001b[1;32m---> 76\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(model\u001b[38;5;241m=\u001b[39mmodel, task\u001b[38;5;241m=\u001b[39mtask, verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRTDETR\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mmodel[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39m_get_name():  \u001b[38;5;66;03m# if RTDETR head\u001b[39;00m\n\u001b[0;32m     78\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RTDETR\n",
            "File \u001b[1;32mc:\\Users\\kensm\\anaconda3\\Lib\\site-packages\\ultralytics\\engine\\model.py:144\u001b[0m, in \u001b[0;36mModel.__init__\u001b[1;34m(self, model, task, verbose)\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new(model, task\u001b[38;5;241m=\u001b[39mtask, verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load(model, task\u001b[38;5;241m=\u001b[39mtask)\n\u001b[0;32m    146\u001b[0m \u001b[38;5;66;03m# Delete super().training for accessing self.model.training\u001b[39;00m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining\n",
            "File \u001b[1;32mc:\\Users\\kensm\\anaconda3\\Lib\\site-packages\\ultralytics\\engine\\model.py:283\u001b[0m, in \u001b[0;36mModel._load\u001b[1;34m(self, weights, task)\u001b[0m\n\u001b[0;32m    280\u001b[0m weights \u001b[38;5;241m=\u001b[39m checks\u001b[38;5;241m.\u001b[39mcheck_model_file_from_stem(weights)  \u001b[38;5;66;03m# add suffix, i.e. yolo26 -> yolo26n.pt\u001b[39;00m\n\u001b[0;32m    282\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(weights)\u001b[38;5;241m.\u001b[39mrpartition(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 283\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt \u001b[38;5;241m=\u001b[39m load_checkpoint(weights)\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtask\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverrides \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset_ckpt_args(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs)\n",
            "File \u001b[1;32mc:\\Users\\kensm\\anaconda3\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:1507\u001b[0m, in \u001b[0;36mload_checkpoint\u001b[1;34m(weight, device, inplace, fuse)\u001b[0m\n\u001b[0;32m   1494\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_checkpoint\u001b[39m(weight, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fuse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m   1495\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load a single model weights.\u001b[39;00m\n\u001b[0;32m   1496\u001b[0m \n\u001b[0;32m   1497\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;124;03m        ckpt (dict): Model checkpoint dictionary.\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1507\u001b[0m     ckpt, weight \u001b[38;5;241m=\u001b[39m torch_safe_load(weight)  \u001b[38;5;66;03m# load ckpt\u001b[39;00m\n\u001b[0;32m   1508\u001b[0m     args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mDEFAULT_CFG_DICT, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(ckpt\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_args\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))}  \u001b[38;5;66;03m# combine model and default args, preferring model args\u001b[39;00m\n\u001b[0;32m   1509\u001b[0m     model \u001b[38;5;241m=\u001b[39m (ckpt\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mema\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m ckpt[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mfloat()  \u001b[38;5;66;03m# FP32 model\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\kensm\\anaconda3\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:1455\u001b[0m, in \u001b[0;36mtorch_safe_load\u001b[1;34m(weight, safe_only)\u001b[0m\n\u001b[0;32m   1453\u001b[0m                 ckpt \u001b[38;5;241m=\u001b[39m torch_load(f, pickle_module\u001b[38;5;241m=\u001b[39msafe_pickle)\n\u001b[0;32m   1454\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1455\u001b[0m             ckpt \u001b[38;5;241m=\u001b[39m torch_load(file, map_location\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1457\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# e.name is missing module name\u001b[39;00m\n\u001b[0;32m   1458\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
            "File \u001b[1;32mc:\\Users\\kensm\\anaconda3\\Lib\\site-packages\\ultralytics\\utils\\patches.py:158\u001b[0m, in \u001b[0;36mtorch_load\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TORCH_1_13 \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights_only\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[0;32m    156\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights_only\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "Cell \u001b[1;32mIn[48], line 14\u001b[0m, in \u001b[0;36m_patched_torch_load\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweights_only\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[0;32m     13\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweights_only\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _original_torch_load(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "Cell \u001b[1;32mIn[17], line 14\u001b[0m, in \u001b[0;36m_patched_torch_load\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweights_only\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[0;32m     13\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweights_only\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _original_torch_load(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "    \u001b[1;31m[... skipping similar frames: _patched_torch_load at line 14 (2968 times)]\u001b[0m\n",
            "Cell \u001b[1;32mIn[17], line 14\u001b[0m, in \u001b[0;36m_patched_torch_load\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweights_only\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[0;32m     13\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweights_only\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _original_torch_load(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "\u001b[1;31mRecursionError\u001b[0m: maximum recursion depth exceeded"
          ]
        }
      ],
      "source": [
        "# Fix for PyTorch 2.6+ weights_only issue (recursion-safe)\n",
        "# Use torch.serialization.load so we never re-enter torch.load and avoid RecursionError\n",
        "# when Ultralytics also patches torch.load.\n",
        "import torch\n",
        "from pathlib import Path\n",
        "from ultralytics import YOLO\n",
        "\n",
        "_real_torch_load = getattr(torch.serialization, \"load\", torch.load)\n",
        "\n",
        "def _patched_torch_load(*args, **kwargs):\n",
        "    if \"weights_only\" not in kwargs:\n",
        "        kwargs[\"weights_only\"] = False\n",
        "    return _real_torch_load(*args, **kwargs)\n",
        "\n",
        "torch.load = _patched_torch_load\n",
        "print(\"‚úì Applied PyTorch 2.6+ compatibility fix for YOLOv8 model loading\")\n",
        "\n",
        "# Initialize YOLOv8 segmentation model exactly once (m-seg = medium; more capacity for finer masks)\n",
        "MODEL_NAME = default_config.get(\"model\", \"yolov8m-seg.pt\")\n",
        "if hasattr(MODEL_NAME, \"strip\"):\n",
        "    MODEL_NAME = str(MODEL_NAME).strip()\n",
        "else:\n",
        "    MODEL_NAME = str(MODEL_NAME)\n",
        "\n",
        "suffix = Path(MODEL_NAME).suffix.lower()\n",
        "if suffix in (\".pt\", \".onnx\", \".engine\", \".yaml\") or (suffix == \"\" and MODEL_NAME.strip()):\n",
        "    model = YOLO(MODEL_NAME)\n",
        "else:\n",
        "    raise ValueError(\n",
        "        f\"Invalid model spec: {MODEL_NAME!r} ‚Äì expected a weights/config path or YOLO name (e.g. yolov8m-seg.pt).\"\n",
        "    )\n",
        "\n",
        "print(f\"‚úì Loaded model: {MODEL_NAME}\")\n",
        "print(f\"‚úì Model parameters: {sum(p.numel() for p in model.model.parameters()):,}\")\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"‚úì Using device: {device}\")\n",
        "if device == \"cpu\":\n",
        "    print(\"‚ö† Warning: Training on CPU will be very slow. Consider enabling GPU in Colab.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì Training on GPU 0: NVIDIA GeForce RTX 4070 Laptop GPU\n",
            "  GPU Memory: 8.59 GB\n",
            "WARNING 'crop_fraction' is deprecated and will be removed in the future.\n",
            "WARNING 'label_smoothing' is deprecated and will be removed in the future.\n",
            "Ultralytics 8.4.12  Python-3.13.5 torch-2.6.0+cu124 CUDA:0 (NVIDIA GeForce RTX 4070 Laptop GPU, 8188MiB)\n",
            "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, angle=1.0, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=C:\\Users\\kensm\\farm-photo-outliner\\sweetpotato_project\\dataset\\data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, end2end=None, epochs=100, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.15, mode=train, model=yolov8m-seg.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=sweetpotato_exp, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=./sweetpotato_project/runs/segment, rect=False, resume=False, retina_masks=False, rle=1.0, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\runs\\segment\\sweetpotato_exp, save_frames=False, save_json=False, save_period=10, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=3\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
            "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
            "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
            "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
            "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
            "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
            "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
            "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
            "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
            "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
            " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
            " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
            " 22        [15, 18, 21]  1   5160761  ultralytics.nn.modules.head.Segment          [3, 32, 192, 16, None, [192, 384, 576]]\n",
            "YOLOv8m-seg summary: 192 layers, 27,241,385 parameters, 27,241,369 gradients, 104.7 GFLOPs\n",
            "\n",
            "Transferred 531/537 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo26n.pt to 'yolo26n.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5.3MB 8.4MB/s 0.6s.6s<0.0ss.5s\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 467.0118.8 MB/s, size: 59.0 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\kensm\\farm-photo-outliner\\sweetpotato_project\\dataset\\train\\labels.cache... 57 images, 3 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 57/57 12.6Mit/s 0.0s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.1 ms, read: 251.185.1 MB/s, size: 44.3 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\kensm\\farm-photo-outliner\\sweetpotato_project\\dataset\\valid\\labels.cache... 5 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 873.8Kit/s 0.0s\n",
            "Plotting labels to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\runs\\segment\\sweetpotato_exp\\labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\runs\\segment\\sweetpotato_exp\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      1/100      6.96G      1.175      3.317      3.605      1.648          0         40        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 1.3s/it 5.1s1.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 3.1it/s 0.3s\n",
            "                   all          5          7     0.0988     0.0741     0.0352     0.0123    0.00299       0.25     0.0126    0.00858\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      2/100      7.01G      1.289      3.351       14.4      1.712          0         21        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 1.8it/s 2.2s0.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 8.5it/s 0.1s\n",
            "                   all          5          7       0.67       0.25    0.00577    0.00196   0.000556     0.0833   0.000305   0.000148\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      3/100      7.31G      1.934      4.132      15.89      2.122          0         35        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 1.9it/s 2.1s0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 7.4it/s 0.1s\n",
            "                   all          5          7          0          0          0          0          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      4/100      7.29G      3.202      5.177      4.294      3.259          0         20        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.1it/s 1.9s0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 13.4it/s 0.1s\n",
            "                   all          5          7          0          0          0          0          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      5/100      7.35G      3.203      4.815      3.894      3.236          0         35        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.0it/s 2.0s0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 13.9it/s 0.1s\n",
            "                   all          5          7          0          0          0          0          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      6/100      7.41G      2.993      4.679      3.733      3.174          0         34        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 1.3it/s 3.1s0.7ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 11.8it/s 0.1s\n",
            "                   all          5          7          0          0          0          0          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      7/100      7.36G      2.885      4.624      3.636      3.084          0         38        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 1.6it/s 2.6s0.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 13.2it/s 0.1s\n",
            "                   all          5          7          0          0          0          0          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      8/100      7.42G      2.791      4.768       3.86      3.055          0         31        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 1.1s/it 4.5s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 12.9it/s 0.1s\n",
            "                   all          5          7          0          0          0          0          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      9/100      7.38G      2.827      4.784      3.508      3.099          0         37        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 1.1it/s 3.7s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 9.7it/s 0.1s\n",
            "                   all          5          7          0          0          0          0          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     10/100      7.39G      2.944      4.531       3.48      3.188          0         35        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 1.2it/s 3.2s0.7ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 15.3it/s 0.1s\n",
            "                   all          5          7          0          0          0          0          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     11/100      7.43G      2.842      4.705      3.494      3.117          0         25        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 1.1s/it 4.3s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 12.6it/s 0.1s\n",
            "                   all          5          7          0          0          0          0          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     12/100      7.43G      2.785      4.741       3.49      3.099          0         32        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 1.2s/it 4.6s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 12.3it/s 0.1s\n",
            "                   all          5          7          0          0          0          0          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     13/100      7.44G      2.651       4.73      3.486      3.001          0         38        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 1.2s/it 4.6s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 12.1it/s 0.1s\n",
            "                   all          5          7          0          0          0          0          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     14/100      7.39G      2.585      4.797      3.427      3.045          0         35        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 1.1it/s 3.7s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 13.6it/s 0.1s\n",
            "                   all          5          7          0          0          0          0          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     15/100      7.39G       2.66       4.43       3.52       3.03          0         40        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 1.2it/s 3.4s0.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 6.4it/s 0.2s\n",
            "                   all          5          7          0          0          0          0          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     16/100      7.36G      2.491      4.265      3.432      2.982          0         23        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 1.8it/s 2.2s0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 8.8it/s 0.1s\n",
            "                   all          5          7          0          0          0          0          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     17/100      7.49G      2.593      4.379      3.434      3.012          0         37        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 1.1s/it 4.4s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 9.2it/s 0.1s\n",
            "                   all          5          7          0          0          0          0          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     18/100      7.46G       2.51      4.277      3.421      2.955          0         37        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 1.3it/s 3.2s0.7ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 13.4it/s 0.1s\n",
            "                   all          5          7          0          0          0          0          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     19/100      7.31G       2.49      4.348      3.379      2.903          0         31        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.2it/s 1.8s0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 13.7it/s 0.1s\n",
            "                   all          5          7          0          0          0          0          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     20/100       7.4G      2.503      4.163      3.276       2.94          0         36        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 1.7it/s 2.3s0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 13.3it/s 0.1s\n",
            "                   all          5          7          0          0          0          0          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     21/100      7.38G       2.52      4.415      3.403      2.958          0         24        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.1it/s 1.9s0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 14.3it/s 0.1s\n",
            "                   all          5          7          0          0          0          0          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     22/100      7.34G      2.425      4.321      3.432      2.953          0         24        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.1it/s 1.9s0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 9.6it/s 0.1s\n",
            "                   all          5          7          0          0          0          0          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     23/100       7.3G      2.393      4.299       3.31      2.904          0         36        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.0it/s 2.0s0.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 9.5it/s 0.1s\n",
            "                   all          5          7          0          0          0          0          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     24/100      7.34G       2.35      4.094      3.321      2.854          0         34        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 1.9it/s 2.1s0.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 10.2it/s 0.1s\n",
            "                   all          5          7          0          0          0          0          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     25/100      7.32G      2.341      4.292      3.288      2.885          0         32        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 1.7it/s 2.4s0.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 6.7it/s 0.1s\n",
            "                   all          5          7          0          0          0          0          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     26/100      7.32G      2.406      4.156      3.214       2.88          0         35        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 1.5it/s 2.6s0.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 4.7it/s 0.2s\n",
            "                   all          5          7          0          0          0          0          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     27/100      7.35G      2.346      4.389      3.141      2.885          0         30        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 1.9it/s 2.1s0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 8.8it/s 0.1s\n",
            "                   all          5          7          0          0          0          0          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     28/100      7.32G      2.303      3.893      3.109      2.825          0         26        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.2it/s 1.9s0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 9.5it/s 0.1s\n",
            "                   all          5          7          0          0          0          0          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     29/100      7.32G       2.33      4.105      3.166      2.842          0         29        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.2it/s 1.8s0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 11.7it/s 0.1s\n",
            "                   all          5          7    0.00152      0.167    0.00114   0.000227    0.00152      0.167    0.00114   0.000114\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     30/100      7.34G      2.427      5.395      3.285      2.937          0         27        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.2it/s 1.8s0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 11.6it/s 0.1s\n",
            "                   all          5          7          0          0          0          0          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     31/100      7.34G      2.242      4.355      3.256      2.791          0         33        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.2it/s 1.8s0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 9.4it/s 0.1s\n",
            "                   all          5          7      0.335      0.167    0.00114   0.000228          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     32/100      7.28G      2.381       4.15      3.367      2.833          0         27        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.3it/s 1.8s0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 11.0it/s 0.1s\n",
            "                   all          5          7          0          0          0          0          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     33/100      7.39G      2.406      4.184       3.25      2.901          0         28        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.1it/s 1.9s0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 10.6it/s 0.1s\n",
            "                   all          5          7          0          0          0          0          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     34/100      7.37G       2.26      3.904      3.242      2.827          0         28        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 1.9it/s 2.1s0.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 8.9it/s 0.1s\n",
            "                   all          5          7          0          0          0          0          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     35/100      7.31G      2.347      3.953      3.325       2.79          0         28        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.1it/s 1.9s0.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 7.8it/s 0.1s\n",
            "                   all          5          7          0          0          0          0   0.000263      0.167    0.00112   0.000112\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     36/100      7.33G      2.454      4.242      3.443      2.848          0         32        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.0it/s 2.0s0.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 8.2it/s 0.1s\n",
            "                   all          5          7          0          0          0          0      0.334      0.167    0.00205   0.000205\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     37/100      7.33G      2.449      4.169      3.311      2.862          0         28        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 1.8it/s 2.2s0.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 5.9it/s 0.2s\n",
            "                   all          5          7    0.00379     0.0833    0.00253   0.000747          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     38/100      7.29G      2.332      4.157      3.258      2.824          0         34        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 1.7it/s 2.3s0.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 7.2it/s 0.1s\n",
            "                   all          5          7      0.228     0.0833     0.0856    0.00883     0.0962     0.0833     0.0277    0.00285\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     39/100      7.36G      2.358      4.311      3.215      2.781          0         37        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.1it/s 1.9s0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 8.8it/s 0.1s\n",
            "                   all          5          7    0.00241      0.167    0.00348    0.00104      0.525     0.0833     0.0821     0.0124\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     40/100      7.33G      2.236      3.983      3.146      2.726          0         38        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.0it/s 2.0s0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 9.0it/s 0.1s\n",
            "                   all          5          7       0.04     0.0833     0.0304     0.0087    0.00114     0.0833    0.00121   0.000242\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     41/100      7.29G      2.307      4.063      3.114      2.745          0         29        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.2it/s 1.8s0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 7.2it/s 0.1s\n",
            "                   all          5          7      0.363     0.0833     0.0142    0.00426      0.363     0.0833     0.0105    0.00316\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     42/100      7.26G      2.186      3.836      3.174      2.712          0         28        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.0it/s 2.0s0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 8.7it/s 0.1s\n",
            "                   all          5          7    0.00879       0.25     0.0316    0.00706          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     43/100      7.28G      2.262      4.287      3.091      2.738          0         34        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 1.9it/s 2.1s0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 9.8it/s 0.1s\n",
            "                   all          5          7     0.0124       0.25     0.0279    0.00671          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     44/100      7.26G      2.269      3.825       3.13      2.714          0         33        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.0it/s 2.0s0.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 11.7it/s 0.1s\n",
            "                   all          5          7    0.00318       0.25    0.00675    0.00181   0.000527     0.0833    0.00122   0.000122\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     45/100      7.33G      2.217      4.237      3.095      2.713          0         30        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 1.7it/s 2.3s0.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 7.2it/s 0.1s\n",
            "                   all          5          7      0.341      0.167     0.0141    0.00268    0.00049     0.0833   0.000405   4.05e-05\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     46/100       7.3G       2.17      3.952      3.082      2.731          0         34        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 1.9it/s 2.1s0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 7.6it/s 0.1s\n",
            "                   all          5          7      0.341     0.0833     0.0108    0.00132    0.00244      0.417    0.00278   0.000314\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     47/100      7.28G      2.206      3.778      3.087       2.67          0         35        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 1.8it/s 2.2s0.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 7.7it/s 0.1s\n",
            "                   all          5          7      0.342      0.167     0.0131    0.00187   0.000427     0.0833   0.000519   5.19e-05\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     48/100      7.31G      2.276      4.117      3.097      2.734          0         25        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 1.9it/s 2.1s0.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 7.0it/s 0.1s\n",
            "                   all          5          7      0.339       0.25    0.00813    0.00221   0.000454     0.0833    0.00088   0.000124\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     49/100      7.35G      2.158      4.191      2.941      2.638          0         53        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.0it/s 2.0s0.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 5.9it/s 0.2s\n",
            "                   all          5          7      0.675       0.25      0.017    0.00435    0.00276      0.417    0.00999      0.002\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     50/100      7.27G      2.177       3.99      2.976      2.677          0         38        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.0it/s 2.0s0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 10.2it/s 0.1s\n",
            "                   all          5          7      0.341       0.25     0.0308    0.00769     0.0107      0.417      0.111     0.0269\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     51/100      7.36G      2.056      4.038      2.833      2.614          0         43        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.3it/s 1.8s0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 11.5it/s 0.1s\n",
            "                   all          5          7     0.0238      0.583     0.0897     0.0113     0.0162      0.333     0.0829     0.0261\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     52/100      7.31G      2.143      3.923      2.969      2.658          0         30        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.3it/s 1.8s0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 11.2it/s 0.1s\n",
            "                   all          5          7       0.02      0.583     0.0267    0.00852     0.0286      0.333      0.166     0.0249\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     53/100      7.31G      2.193       3.87      2.911       2.69          0         29        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.3it/s 1.7s0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 11.7it/s 0.1s\n",
            "                   all          5          7    0.00255       0.25     0.0037    0.00136   0.000931      0.333    0.00114   0.000114\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     54/100      7.32G      2.087      3.841      2.883      2.617          0         25        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.3it/s 1.8s0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 11.4it/s 0.1s\n",
            "                   all          5          7    0.00161       0.25    0.00397    0.00148          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     55/100      7.29G      2.127      3.841      2.839      2.615          0         34        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.2it/s 1.8s0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 11.4it/s 0.1s\n",
            "                   all          5          7    0.00117       0.25    0.00359    0.00106          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     56/100       7.3G      2.129      4.052      2.912      2.658          0         33        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.3it/s 1.7s0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 11.0it/s 0.1s\n",
            "                   all          5          7    0.00249       0.25     0.0079    0.00298          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     57/100      7.36G      2.138      4.179      2.942      2.604          0         32        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.3it/s 1.7s0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 11.5it/s 0.1s\n",
            "                   all          5          7      0.337       0.25     0.0111    0.00415          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     58/100      7.33G      2.058      3.996      2.909      2.557          0         38        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.3it/s 1.8s0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 11.7it/s 0.1s\n",
            "                   all          5          7      0.339       0.25     0.0186    0.00729   0.000407     0.0833   0.000318   3.18e-05\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     59/100      7.31G      2.114      3.871      2.992       2.58          0         38        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.3it/s 1.7s0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 11.7it/s 0.1s\n",
            "                   all          5          7    0.00598       0.25     0.0238    0.00844   0.000446     0.0833   0.000394   3.94e-05\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     60/100       7.3G      2.079      3.923      2.873      2.559          0         39        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.3it/s 1.7s0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 10.7it/s 0.1s\n",
            "                   all          5          7    0.00399       0.25     0.0283     0.0106   0.000499     0.0833   0.000428   4.28e-05\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     61/100      7.37G      1.995      3.705      2.901      2.572          0         25        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.1it/s 1.9s0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 11.3it/s 0.1s\n",
            "                   all          5          7    0.00236      0.333      0.034     0.0105   0.000591     0.0833   0.000525   5.25e-05\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     62/100      7.31G      2.054      4.074      2.939      2.604          0         40        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.3it/s 1.8s0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 12.1it/s 0.1s\n",
            "                   all          5          7    0.00282      0.333     0.0292     0.0059   0.000706     0.0833   0.000452   4.52e-05\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     63/100      7.36G       2.12      3.906      2.839      2.599          0         35        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.3it/s 1.7s0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 11.7it/s 0.1s\n",
            "                   all          5          7     0.0023       0.25     0.0186     0.0037          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     64/100      7.28G      2.013      3.911      2.756      2.554          0         39        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.3it/s 1.7s0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 12.1it/s 0.1s\n",
            "                   all          5          7    0.00156      0.167     0.0114    0.00171          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     65/100      7.31G       2.03       3.67      2.869      2.589          0         34        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.2it/s 1.8s0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 12.3it/s 0.1s\n",
            "                   all          5          7    0.00155      0.167    0.00742    0.00189          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     66/100      7.31G      2.095      4.107      2.759      2.659          0         47        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.3it/s 1.7s0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 12.2it/s 0.1s\n",
            "                   all          5          7    0.00235       0.25    0.00737    0.00142          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     67/100      7.28G      2.115      3.912       2.92       2.57          0         42        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.3it/s 1.7s0.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 10.8it/s 0.1s\n",
            "                   all          5          7    0.00154      0.167    0.00305   0.000874          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     68/100      7.36G      1.959      3.945      2.817      2.486          0         41        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.3it/s 1.7s0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 11.5it/s 0.1s\n",
            "                   all          5          7    0.00141      0.167    0.00397    0.00104          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     69/100      7.35G      2.006      3.796      2.908      2.546          0         33        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.3it/s 1.7s0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 12.3it/s 0.1s\n",
            "                   all          5          7    0.00157      0.167    0.00547    0.00156   0.000784     0.0833   0.000683   6.83e-05\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     70/100      7.29G      1.989       3.87      2.703      2.571          0         33        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.1it/s 1.9s0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 11.6it/s 0.1s\n",
            "                   all          5          7    0.00328      0.333     0.0156     0.0029          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     71/100      7.28G      1.989      3.854      2.715       2.55          0         45        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.3it/s 1.7s0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 12.4it/s 0.1s\n",
            "                   all          5          7    0.00353      0.333     0.0268    0.00632   0.000882     0.0833   0.000576   5.76e-05\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     72/100      7.38G      1.872      3.799      2.746      2.458          0         33        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.3it/s 1.7s0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 12.8it/s 0.1s\n",
            "                   all          5          7    0.00333      0.333     0.0254    0.00548          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     73/100      7.29G      1.928      3.722      2.757      2.489          0         35        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.3it/s 1.8s0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 12.5it/s 0.1s\n",
            "                   all          5          7    0.00312      0.333     0.0295    0.00845    0.00186      0.417    0.00428   0.000804\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     74/100      7.32G      2.028      3.597      2.803      2.531          0         26        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.3it/s 1.7s0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 11.6it/s 0.1s\n",
            "                   all          5          7    0.00275      0.333     0.0268    0.00824    0.00165      0.417    0.00969    0.00286\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     75/100      7.33G      2.133      4.037      2.883      2.574          0         46        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.3it/s 1.7s0.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 11.4it/s 0.1s\n",
            "                   all          5          7    0.00359      0.667     0.0365    0.00906    0.00225        0.5      0.068    0.00996\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     76/100      7.32G       2.03      3.818      2.906      2.548          0         45        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.3it/s 1.7s0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 11.2it/s 0.1s\n",
            "                   all          5          7    0.00373      0.667     0.0269    0.00635     0.0228      0.333      0.334     0.0347\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     77/100      7.29G      1.977      3.622      2.834      2.499          0         38        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.3it/s 1.7s0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 12.1it/s 0.1s\n",
            "                   all          5          7    0.00435      0.667     0.0343    0.00684      0.392      0.333      0.334     0.0351\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     78/100      7.38G      2.059      3.762      2.868      2.549          0         27        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.3it/s 1.7s0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 11.9it/s 0.1s\n",
            "                   all          5          7    0.00494      0.667      0.103     0.0395      0.395      0.333      0.248     0.0506\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     79/100      7.32G      1.985       3.62      2.625       2.44          0         44        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.3it/s 1.7s0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 12.2it/s 0.1s\n",
            "                   all          5          7    0.00794      0.167     0.0877     0.0312      0.689      0.333      0.129     0.0233\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     80/100      7.37G      2.202      4.385      3.023      2.655          0         38        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.3it/s 1.8s0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 12.4it/s 0.1s\n",
            "                   all          5          7    0.00996      0.167     0.0884     0.0426      0.699      0.333      0.193     0.0432\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     81/100      7.26G      2.049      3.572      2.818      2.482          0         39        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.3it/s 1.7s0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 7.9it/s 0.1s\n",
            "                   all          5          7    0.00989      0.167     0.0888     0.0432       0.18      0.417      0.165     0.0438\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     82/100       7.3G      2.019      3.976      2.864      2.529          0         31        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.3it/s 1.7s0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 12.1it/s 0.1s\n",
            "                   all          5          7    0.00592       0.25     0.0872     0.0429      0.149      0.417      0.165     0.0449\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     83/100      7.34G      2.061       3.71      2.751      2.471          0         25        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.3it/s 1.7s0.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 11.5it/s 0.1s\n",
            "                   all          5          7     0.0323      0.417      0.118     0.0462      0.707      0.333      0.248     0.0694\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     84/100      7.31G      2.001      3.658      2.782       2.47          0         28        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.3it/s 1.7s0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 12.0it/s 0.1s\n",
            "                   all          5          7     0.0739      0.417     0.0788     0.0258      0.713      0.333      0.207     0.0557\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     85/100      7.32G      1.978      3.822      2.662      2.501          0         42        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.3it/s 1.7s0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 10.7it/s 0.1s\n",
            "                   all          5          7     0.0137      0.583     0.0957     0.0326      0.742      0.333      0.414     0.0689\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     86/100      7.32G       1.93      3.921      2.727      2.435          0         28        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.3it/s 1.7s0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 12.1it/s 0.1s\n",
            "                   all          5          7     0.0082      0.667      0.107     0.0326      0.729      0.333      0.248     0.0571\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     87/100      7.33G       1.95      3.889      2.688      2.426          0         36        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.2it/s 1.8s0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 8.3it/s 0.1s\n",
            "                   all          5          7    0.00373      0.667     0.0368     0.0117       0.42      0.333      0.178     0.0261\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     88/100      7.35G      1.912      3.451      2.737      2.459          0         19        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.2it/s 1.8s0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 10.9it/s 0.1s\n",
            "                   all          5          7    0.00348      0.667     0.0337     0.0106    0.00898      0.333     0.0286     0.0102\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     89/100      7.31G      1.944      3.756      2.641      2.405          0         36        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.3it/s 1.8s0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 8.6it/s 0.1s\n",
            "                   all          5          7    0.00336      0.667     0.0309    0.00843      0.346      0.333     0.0288    0.00959\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     90/100      7.27G      1.845      3.538        2.6      2.381          0         45        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.3it/s 1.7s0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 10.6it/s 0.1s\n",
            "                   all          5          7    0.00337      0.667     0.0301    0.00729      0.346      0.333      0.033    0.00827\n",
            "Closing dataloader mosaic\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     91/100       7.3G      2.018      3.658      3.234      2.635          0         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 1.6s/it 6.3s1.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 4.7it/s 0.2s\n",
            "                   all          5          7    0.00326      0.667     0.0295    0.00648    0.00831      0.417     0.0165    0.00628\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     92/100      7.26G      1.938      3.438      3.215      2.675          0         10        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.0it/s 2.0s0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 9.4it/s 0.1s\n",
            "                   all          5          7    0.00321      0.667     0.0314    0.00671    0.00769      0.417     0.0172    0.00675\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     93/100       7.3G      2.058      3.528      3.117      2.813          0         10        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.0it/s 2.0s0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 8.9it/s 0.1s\n",
            "                   all          5          7    0.00254      0.583     0.0218    0.00651    0.00885      0.417     0.0179     0.0073\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     94/100      7.31G      1.941      3.519      3.064      2.686          0         13        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.1it/s 1.9s0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 7.4it/s 0.1s\n",
            "                   all          5          7    0.00254      0.583     0.0201    0.00537     0.0087      0.417     0.0188    0.00748\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     95/100      7.27G      1.878      3.473      2.948      2.635          0         11        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.1it/s 1.9s0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 7.0it/s 0.1s\n",
            "                   all          5          7    0.00259      0.583     0.0212    0.00695     0.0121      0.417     0.0208    0.00886\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     96/100       7.3G      1.991      3.571      2.915      2.805          0         10        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.2it/s 1.8s0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 9.1it/s 0.1s\n",
            "                   all          5          7     0.0026      0.583     0.0241    0.00781     0.0107      0.333     0.0396     0.0127\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     97/100      7.26G       1.97      3.454      2.939      2.644          0         12        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.1it/s 1.9s0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 6.9it/s 0.1s\n",
            "                   all          5          7    0.00266      0.583     0.0227    0.00698     0.0153      0.417     0.0202    0.00865\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     98/100      7.25G      1.934      3.605      2.798      2.659          0         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.1it/s 1.9s0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 11.6it/s 0.1s\n",
            "                   all          5          7      0.002        0.5     0.0199     0.0073      0.684      0.333      0.178     0.0251\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     99/100      7.24G      1.923      3.601      2.755      2.577          0          9        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.1it/s 1.9s0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 7.6it/s 0.1s\n",
            "                   all          5          7      0.002        0.5     0.0187    0.00709       0.35      0.333      0.176     0.0251\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K    100/100      7.25G      1.947      3.609      2.912      2.562          0         13        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.0it/s 2.0s0.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 10.0it/s 0.1s\n",
            "                   all          5          7    0.00825        0.5     0.0229    0.00815      0.349      0.333      0.122     0.0204\n",
            "\n",
            "100 epochs completed in 0.102 hours.\n",
            "Optimizer stripped from C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\runs\\segment\\sweetpotato_exp\\weights\\last.pt, 54.8MB\n",
            "Optimizer stripped from C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\runs\\segment\\sweetpotato_exp\\weights\\best.pt, 54.8MB\n",
            "\n",
            "Validating C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\runs\\segment\\sweetpotato_exp\\weights\\best.pt...\n",
            "Ultralytics 8.4.12  Python-3.13.5 torch-2.6.0+cu124 CUDA:0 (NVIDIA GeForce RTX 4070 Laptop GPU, 8188MiB)\n",
            "YOLOv8m-seg summary (fused): 106 layers, 27,224,121 parameters, 0 gradients, 104.3 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 5.4it/s 0.2s\n",
            "                   all          5          7     0.0324      0.417      0.118     0.0462      0.706      0.333      0.248     0.0694\n",
            "              Diseased          1          1     0.0242          1     0.0905       0.01      0.119          1      0.497       0.11\n",
            "               Healthy          2          4     0.0731       0.25      0.263      0.129          1          0      0.246     0.0985\n",
            "        Non-determined          2          2          0          0          0          0          1          0          0          0\n",
            "Speed: 0.7ms preprocess, 22.2ms inference, 0.0ms loss, 3.6ms postprocess per image\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\runs\\segment\\sweetpotato_exp\u001b[0m\n",
            "\n",
            "‚úì Training completed successfully!\n",
            "‚úì Best model saved to: C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\runs\\segment\\sweetpotato_exp/weights/best.pt\n"
          ]
        }
      ],
      "source": [
        "# Train the model with error handling\n",
        "# Ensure GPU is used if available\n",
        "\n",
        "# Get device from GPU diagnostics cell or detect automatically\n",
        "if 'TRAINING_DEVICE' in globals():\n",
        "    train_device = TRAINING_DEVICE\n",
        "    # Convert 'cuda' to '0' for YOLO\n",
        "    if train_device == 'cuda' and torch.cuda.is_available():\n",
        "        train_device = '0'\n",
        "elif 'device' in globals() and hasattr(device, 'type') and device.type == 'cuda':\n",
        "    train_device = '0'  # Use first GPU\n",
        "elif torch.cuda.is_available():\n",
        "    train_device = '0'  # Use first GPU\n",
        "else:\n",
        "    train_device = 'cpu'  # Fallback to CPU\n",
        "\n",
        "# Display device info\n",
        "if train_device == '0' and torch.cuda.is_available():\n",
        "    print(f\"‚úì Training on GPU {train_device}: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"  GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "elif train_device == 'cpu':\n",
        "    print(f\"‚ö† Training on CPU (GPU not available)\")\n",
        "    print(\"  Install CUDA-enabled PyTorch to use GPU\")\n",
        "    print(\"  Run: pip uninstall -y torch torchvision torchaudio\")\n",
        "    print(\"       pip install --index-url https://download.pytorch.org/whl/cu121 torch torchvision torchaudio\")\n",
        "\n",
        "try:\n",
        "    results = model.train(\n",
        "        data=data_yaml_path,\n",
        "        device=train_device,  # Explicitly set device: '0' for GPU, 'cpu' for CPU\n",
        "        epochs=default_config['epochs'],\n",
        "        imgsz=default_config['imgsz'],\n",
        "        batch=default_config['batch'],\n",
        "        optimizer=default_config['optimizer'],\n",
        "        lr0=default_config['lr0'],\n",
        "        lrf=default_config['lrf'],\n",
        "        momentum=default_config['momentum'],\n",
        "        weight_decay=default_config['weight_decay'],\n",
        "        warmup_epochs=default_config['warmup_epochs'],\n",
        "        warmup_momentum=default_config['warmup_momentum'],\n",
        "        warmup_bias_lr=default_config['warmup_bias_lr'],\n",
        "        box=default_config['box'],\n",
        "        cls=default_config['cls'],\n",
        "        dfl=default_config['dfl'],\n",
        "        label_smoothing=default_config['label_smoothing'],\n",
        "        nbs=default_config['nbs'],\n",
        "        hsv_h=default_config['hsv_h'],\n",
        "        hsv_s=default_config['hsv_s'],\n",
        "        hsv_v=default_config['hsv_v'],\n",
        "        degrees=default_config['degrees'],\n",
        "        translate=default_config['translate'],\n",
        "        scale=default_config['scale'],\n",
        "        shear=default_config['shear'],\n",
        "        perspective=default_config['perspective'],\n",
        "        flipud=default_config['flipud'],\n",
        "        fliplr=default_config['fliplr'],\n",
        "        mosaic=default_config['mosaic'],\n",
        "        mixup=default_config['mixup'],\n",
        "        copy_paste=default_config['copy_paste'],\n",
        "        auto_augment=default_config['auto_augment'],\n",
        "        erasing=default_config['erasing'],\n",
        "        crop_fraction=default_config['crop_fraction'],\n",
        "        save=True,\n",
        "        save_period=10,  # Save checkpoint every 10 epochs\n",
        "        project=f'{WORK_DIR}/runs/segment',\n",
        "        name='sweetpotato_exp',\n",
        "        exist_ok=True,\n",
        "        pretrained=True,\n",
        "        verbose=True,\n",
        "        seed=42,\n",
        "        deterministic=True,\n",
        "        single_cls=False,\n",
        "        rect=False,\n",
        "        cos_lr=False,\n",
        "        close_mosaic=10,\n",
        "        resume=False,\n",
        "        amp=True,  # Automatic Mixed Precision for faster training\n",
        "        fraction=1.0,\n",
        "        profile=False,\n",
        "        freeze=None,\n",
        "        # Multi-scale training\n",
        "        multi_scale=False,\n",
        "        overlap_mask=True,\n",
        "        mask_ratio=4,\n",
        "        dropout=0.0\n",
        "    )\n",
        "    \n",
        "    print(\"\\n‚úì Training completed successfully!\")\n",
        "    print(f\"‚úì Best model saved to: {results.save_dir}/weights/best.pt\")\n",
        "    \n",
        "except RuntimeError as e:\n",
        "    if \"out of memory\" in str(e).lower() or \"oom\" in str(e).lower():\n",
        "        print(\"\\n‚ö† GPU Out of Memory! Trying with smaller batch size...\")\n",
        "        # Retry with smaller batch size\n",
        "        torch.cuda.empty_cache()\n",
        "        default_config['batch'] = max(4, default_config['batch'] // 2)\n",
        "        print(f\"Retrying with batch size: {default_config['batch']}\")\n",
        "        # Re-run training with smaller batch\n",
        "        # (User should re-run the cell)\n",
        "    else:\n",
        "        raise e\n",
        "except Exception as e:\n",
        "    print(f\"\\n‚úó Training failed with error: {e}\")\n",
        "    raise e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Evaluation & Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì Loaded best model: ./sweetpotato_project/runs/segment/sweetpotato_exp/weights/best.pt\n"
          ]
        }
      ],
      "source": [
        "# Load the best model from training\n",
        "best_model_path = f'{WORK_DIR}/runs/segment/sweetpotato_exp/weights/best.pt'\n",
        "if not os.path.exists(best_model_path):\n",
        "    # Try to find the latest run\n",
        "    runs_dir = f'{WORK_DIR}/runs/segment'\n",
        "    if os.path.exists(runs_dir):\n",
        "        runs = sorted([d for d in os.listdir(runs_dir) if os.path.isdir(os.path.join(runs_dir, d))])\n",
        "        if runs:\n",
        "            latest_run = runs[-1]\n",
        "            best_model_path = f'{runs_dir}/{latest_run}/weights/best.pt'\n",
        "\n",
        "if os.path.exists(best_model_path):\n",
        "    model = YOLO(best_model_path)\n",
        "    print(f\"‚úì Loaded best model: {best_model_path}\")\n",
        "else:\n",
        "    print(\"‚ö† Best model not found, using last checkpoint\")\n",
        "    model = YOLO(model_name)  # Fallback to pretrained"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating on validation set...\n",
            "Ultralytics 8.4.12  Python-3.13.5 torch-2.6.0+cu124 CUDA:0 (NVIDIA GeForce RTX 4070 Laptop GPU, 8188MiB)\n",
            "YOLOv8m-seg summary (fused): 105 layers, 27,224,121 parameters, 0 gradients, 104.3 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 174.374.4 MB/s, size: 44.3 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\kensm\\farm-photo-outliner\\sweetpotato_project\\dataset\\valid\\labels.cache... 5 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 1.2Mit/s 0.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 4.2s/it 4.2s\n",
            "                   all          5          7     0.0342     0.0833     0.0356     0.0108   0.000682     0.0833   0.000918   0.000375\n",
            "              Diseased          1          1          0          0     0.0711     0.0182          0          0          0          0\n",
            "               Healthy          2          4      0.103       0.25     0.0358     0.0143    0.00204       0.25    0.00275    0.00112\n",
            "        Non-determined          2          2          0          0          0          0          0          0          0          0\n",
            "Speed: 3.8ms preprocess, 90.4ms inference, 0.0ms loss, 11.9ms postprocess per image\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\val\u001b[0m\n",
            "\n",
            "Evaluating on test set...\n",
            "Ultralytics 8.4.12  Python-3.13.5 torch-2.6.0+cu124 CUDA:0 (NVIDIA GeForce RTX 4070 Laptop GPU, 8188MiB)\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 384.194.2 MB/s, size: 62.0 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\kensm\\farm-photo-outliner\\sweetpotato_project\\dataset\\test\\labels... 3 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 865.1it/s 0.0s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\kensm\\farm-photo-outliner\\sweetpotato_project\\dataset\\test\\labels.cache\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 4.1s/it 4.1s\n",
            "                   all          3          3    0.00476      0.333     0.0415     0.0135    0.00476      0.333     0.0255    0.00255\n",
            "              Diseased          1          1     0.0143          1      0.124     0.0406     0.0143          1     0.0765    0.00765\n",
            "               Healthy          1          1          0          0          0          0          0          0          0          0\n",
            "        Non-determined          1          1          0          0          0          0          0          0          0          0\n",
            "Speed: 4.2ms preprocess, 74.2ms inference, 0.0ms loss, 13.0ms postprocess per image\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\val2\u001b[0m\n",
            "\n",
            "==================================================\n",
            "VALIDATION METRICS\n",
            "==================================================\n",
            "mAP50 (bbox): 0.0356\n",
            "mAP50-95 (bbox): 0.0108\n",
            "mAP50 (mask): 0.0009\n",
            "mAP50-95 (mask): 0.0004\n",
            "Precision: 0.0342\n",
            "Recall: 0.0833\n",
            "\n",
            "==================================================\n",
            "TEST METRICS\n",
            "==================================================\n",
            "mAP50 (bbox): 0.0415\n",
            "mAP50-95 (bbox): 0.0135\n",
            "mAP50 (mask): 0.0255\n",
            "mAP50-95 (mask): 0.0026\n",
            "Precision: 0.0048\n",
            "Recall: 0.3333\n"
          ]
        }
      ],
      "source": [
        "# Evaluate on validation and test sets\n",
        "print(\"Evaluating on validation set...\")\n",
        "val_metrics = model.val(data=data_yaml_path, split='val')\n",
        "\n",
        "print(\"\\nEvaluating on test set...\")\n",
        "test_metrics = model.val(data=data_yaml_path, split='test')\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"VALIDATION METRICS\")\n",
        "print(\"=\"*50)\n",
        "print(f\"mAP50 (bbox): {val_metrics.box.map50:.4f}\")\n",
        "print(f\"mAP50-95 (bbox): {val_metrics.box.map:.4f}\")\n",
        "print(f\"mAP50 (mask): {val_metrics.seg.map50:.4f}\")\n",
        "print(f\"mAP50-95 (mask): {val_metrics.seg.map:.4f}\")\n",
        "print(f\"Precision: {val_metrics.box.mp:.4f}\")\n",
        "print(f\"Recall: {val_metrics.box.mr:.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"TEST METRICS\")\n",
        "print(\"=\"*50)\n",
        "print(f\"mAP50 (bbox): {test_metrics.box.map50:.4f}\")\n",
        "print(f\"mAP50-95 (bbox): {test_metrics.box.map:.4f}\")\n",
        "print(f\"mAP50 (mask): {test_metrics.seg.map50:.4f}\")\n",
        "print(f\"mAP50-95 (mask): {test_metrics.seg.map:.4f}\")\n",
        "print(f\"Precision: {test_metrics.box.mp:.4f}\")\n",
        "print(f\"Recall: {test_metrics.box.mr:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate confusion matrix\n",
        "from ultralytics.utils.plotting import Annotator\n",
        "\n",
        "confusion_matrix_path = f'{WORK_DIR}/runs/segment/sweetpotato_exp/confusion_matrix.png'\n",
        "if os.path.exists(confusion_matrix_path):\n",
        "    img = cv2.imread(confusion_matrix_path)\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "    plt.title('Confusion Matrix', fontsize=16)\n",
        "    plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    print(\"‚úì Confusion matrix displayed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running inference on 3 test images...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  8.86it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "CUSTOM ROOT METRICS\n",
            "==================================================\n",
            "Average roots per image: 1.50\n",
            "Total area coverage (avg): 164341.00 pixels\n",
            "Average root area: 153383.25 pixels\n",
            "\n",
            "Size Distribution:\n",
            "  Small: 1\n",
            "  Medium: 0\n",
            "  Large: 2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Custom metrics: Root count, area coverage, size distribution\n",
        "def calculate_custom_metrics(results_list, class_names):\n",
        "    \"\"\"Calculate root-specific metrics\"\"\"\n",
        "    metrics = {\n",
        "        'root_counts': [],\n",
        "        'total_areas': [],\n",
        "        'avg_areas': [],\n",
        "        'size_distribution': {'small': 0, 'medium': 0, 'large': 0}\n",
        "    }\n",
        "    \n",
        "    for result in results_list:\n",
        "        if result.masks is not None:\n",
        "            root_count = len(result.boxes)\n",
        "            total_area = 0\n",
        "            areas = []\n",
        "            \n",
        "            for mask in result.masks.data:\n",
        "                area = mask.sum().item()\n",
        "                total_area += area\n",
        "                areas.append(area)\n",
        "            \n",
        "            metrics['root_counts'].append(root_count)\n",
        "            metrics['total_areas'].append(total_area)\n",
        "            if areas:\n",
        "                metrics['avg_areas'].append(np.mean(areas))\n",
        "                \n",
        "                # Size distribution (based on area percentiles)\n",
        "                for area in areas:\n",
        "                    if area < np.percentile(areas, 33):\n",
        "                        metrics['size_distribution']['small'] += 1\n",
        "                    elif area < np.percentile(areas, 67):\n",
        "                        metrics['size_distribution']['medium'] += 1\n",
        "                    else:\n",
        "                        metrics['size_distribution']['large'] += 1\n",
        "    \n",
        "    return metrics\n",
        "\n",
        "# Run inference on test set for custom metrics\n",
        "test_images_dir = os.path.join(DATASET_DIR, 'test', 'images')\n",
        "if not os.path.exists(test_images_dir):\n",
        "    test_images_dir = os.path.join(DATASET_DIR, 'test')\n",
        "\n",
        "test_images = [f for f in os.listdir(test_images_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "test_results = []\n",
        "\n",
        "print(f\"Running inference on {len(test_images)} test images...\")\n",
        "for img_file in tqdm(test_images[:20]):  # Limit to 20 for demo\n",
        "    img_path = os.path.join(test_images_dir, img_file)\n",
        "    results = model.predict(img_path, conf=0.25, iou=0.45, verbose=False)\n",
        "    test_results.extend(results)\n",
        "\n",
        "# Calculate custom metrics\n",
        "custom_metrics = calculate_custom_metrics(test_results, data_config.get('names', []))\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"CUSTOM ROOT METRICS\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Average roots per image: {np.mean(custom_metrics['root_counts']):.2f}\")\n",
        "print(f\"Total area coverage (avg): {np.mean(custom_metrics['total_areas']):.2f} pixels\")\n",
        "print(f\"Average root area: {np.mean(custom_metrics['avg_areas']):.2f} pixels\")\n",
        "print(f\"\\nSize Distribution:\")\n",
        "print(f\"  Small: {custom_metrics['size_distribution']['small']}\")\n",
        "print(f\"  Medium: {custom_metrics['size_distribution']['medium']}\")\n",
        "print(f\"  Large: {custom_metrics['size_distribution']['large']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì Saved flagged images to ./sweetpotato_project/runs/segment/sweetpotato_exp\\low_confidence_predictions.csv\n",
            "\n",
            "Flagged 0 images for re-annotation\n"
          ]
        }
      ],
      "source": [
        "# Active Learning: Flag low-confidence predictions\n",
        "def flag_low_confidence(results_list, confidence_threshold=0.5, output_dir=None):\n",
        "    \"\"\"Flag images with low-confidence predictions for re-annotation\"\"\"\n",
        "    flagged_images = []\n",
        "    \n",
        "    for result in results_list:\n",
        "        if result.boxes is not None and len(result.boxes) > 0:\n",
        "            confidences = result.boxes.conf.cpu().numpy()\n",
        "            avg_confidence = np.mean(confidences)\n",
        "            min_confidence = np.min(confidences)\n",
        "            \n",
        "            if avg_confidence < confidence_threshold or min_confidence < confidence_threshold * 0.7:\n",
        "                flagged_images.append({\n",
        "                    'image': result.path,\n",
        "                    'avg_confidence': avg_confidence,\n",
        "                    'min_confidence': min_confidence,\n",
        "                    'num_detections': len(result.boxes)\n",
        "                })\n",
        "    \n",
        "    if output_dir:\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "        df = pd.DataFrame(flagged_images)\n",
        "        csv_path = os.path.join(output_dir, 'low_confidence_predictions.csv')\n",
        "        df.to_csv(csv_path, index=False)\n",
        "        print(f\"‚úì Saved flagged images to {csv_path}\")\n",
        "    \n",
        "    return flagged_images\n",
        "\n",
        "# Flag low-confidence predictions\n",
        "flagged = flag_low_confidence(test_results, confidence_threshold=0.5, \n",
        "                              output_dir=f'{WORK_DIR}/runs/segment/sweetpotato_exp')\n",
        "\n",
        "print(f\"\\nFlagged {len(flagged)} images for re-annotation\")\n",
        "if flagged:\n",
        "    print(\"\\nTop 5 lowest confidence predictions:\")\n",
        "    flagged_sorted = sorted(flagged, key=lambda x: x['avg_confidence'])\n",
        "    for i, item in enumerate(flagged_sorted[:5], 1):\n",
        "        print(f\"{i}. {os.path.basename(item['image'])}: avg_conf={item['avg_confidence']:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Inference & Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running inference on 3 test images...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/3 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "1 label saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "1 label saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:00<00:00, 16.60it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 17.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "‚úì Inference complete. Results saved to ./sweetpotato_project/outputs/predictions\n",
            "‚úì Total predictions: 3\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Run inference on test images\n",
        "output_dir = f'{WORK_DIR}/outputs/predictions'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "test_images = [f for f in os.listdir(test_images_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "test_images = test_images[:20]  # Process 20 images\n",
        "\n",
        "print(f\"Running inference on {len(test_images)} test images...\")\n",
        "\n",
        "all_predictions = []\n",
        "\n",
        "for img_file in tqdm(test_images):\n",
        "    img_path = os.path.join(test_images_dir, img_file)\n",
        "    \n",
        "    # Run prediction\n",
        "    results = model.predict(\n",
        "        img_path,\n",
        "        conf=0.25,\n",
        "        iou=0.45,\n",
        "        save=True,\n",
        "        save_txt=True,\n",
        "        save_conf=True,\n",
        "        project=output_dir,\n",
        "        name='predictions',\n",
        "        exist_ok=True\n",
        "    )\n",
        "    \n",
        "    # Extract prediction data\n",
        "    result = results[0]\n",
        "    if result.boxes is not None:\n",
        "        for i, box in enumerate(result.boxes):\n",
        "            bbox = box.xyxy[0].cpu().numpy()  # [x1, y1, x2, y2]\n",
        "            conf = box.conf[0].cpu().item()\n",
        "            cls = int(box.cls[0].cpu().item())\n",
        "            \n",
        "            # Get mask polygon if available\n",
        "            mask_polygon = None\n",
        "            if result.masks is not None and i < len(result.masks.data):\n",
        "                mask = result.masks.data[i].cpu().numpy()\n",
        "                # Convert mask to polygon\n",
        "                contours, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "                if contours:\n",
        "                    # Get largest contour\n",
        "                    largest_contour = max(contours, key=cv2.contourArea)\n",
        "                    mask_polygon = largest_contour.reshape(-1, 2).tolist()\n",
        "            \n",
        "            all_predictions.append({\n",
        "                'image_name': img_file,\n",
        "                'bbox_x1': bbox[0],\n",
        "                'bbox_y1': bbox[1],\n",
        "                'bbox_x2': bbox[2],\n",
        "                'bbox_y2': bbox[3],\n",
        "                'confidence': conf,\n",
        "                'class': cls,\n",
        "                'class_name': data_config.get('names', ['unknown'])[cls] if cls < len(data_config.get('names', [])) else 'unknown',\n",
        "                'mask_polygon': str(mask_polygon) if mask_polygon else None\n",
        "            })\n",
        "\n",
        "print(f\"\\n‚úì Inference complete. Results saved to {output_dir}\")\n",
        "print(f\"‚úì Total predictions: {len(all_predictions)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì Predictions saved to: ./sweetpotato_project/runs/segment/sweetpotato_exp/predictions.csv\n",
            "\n",
            "First few predictions:\n",
            "                                          image_name     bbox_x1   bbox_y1  \\\n",
            "0  Hr-23_jpg.rf.b6b8a13ec4bf745687738e0663c99023.jpg  243.222412  9.757080   \n",
            "1  Hr-23_jpg.rf.b6b8a13ec4bf745687738e0663c99023.jpg  272.502380  8.479111   \n",
            "2  Inf-44_jpg.rf.460ec20282d0e0c9daece65791d1e0ba...    0.000000  2.480560   \n",
            "\n",
            "      bbox_x2     bbox_y2  confidence  class      class_name  \\\n",
            "0  516.458374  327.337585    0.624851      2  Non-determined   \n",
            "1  633.675110  515.169922    0.509105      2  Non-determined   \n",
            "2  638.666870  491.609955    0.578858      0        Diseased   \n",
            "\n",
            "                                        mask_polygon  \n",
            "0  [[414, 106], [414, 115], [416, 117], [416, 118...  \n",
            "1  [[507, 263], [506, 264], [502, 264], [501, 265...  \n",
            "2  [[0, 2], [0, 133], [1, 133], [2, 134], [2, 136...  \n"
          ]
        }
      ],
      "source": [
        "# Save predictions to CSV\n",
        "df_predictions = pd.DataFrame(all_predictions)\n",
        "csv_path = f'{WORK_DIR}/runs/segment/sweetpotato_exp/predictions.csv'\n",
        "df_predictions.to_csv(csv_path, index=False)\n",
        "print(f\"‚úì Predictions saved to: {csv_path}\")\n",
        "print(f\"\\nFirst few predictions:\")\n",
        "print(df_predictions.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Visualize predictions on sample images\n",
        "def visualize_predictions(image_path, results, save_path=None):\n",
        "    \"\"\"Visualize predictions with masks and bounding boxes\"\"\"\n",
        "    img = cv2.imread(image_path)\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    \n",
        "    result = results[0]\n",
        "    \n",
        "    # Draw masks\n",
        "    if result.masks is not None:\n",
        "        for i, mask in enumerate(result.masks.data):\n",
        "            mask_np = mask.cpu().numpy().astype(np.uint8)\n",
        "            # Create colored overlay\n",
        "            color = np.random.randint(0, 255, 3).tolist()\n",
        "            colored_mask = np.zeros_like(img_rgb)\n",
        "            colored_mask[mask_np > 0] = color\n",
        "            img_rgb = cv2.addWeighted(img_rgb, 0.7, colored_mask, 0.3, 0)\n",
        "    \n",
        "    # Draw bounding boxes\n",
        "    if result.boxes is not None:\n",
        "        for box in result.boxes:\n",
        "            bbox = box.xyxy[0].cpu().numpy().astype(int)\n",
        "            conf = box.conf[0].cpu().item()\n",
        "            cls = int(box.cls[0].cpu().item())\n",
        "            \n",
        "            cv2.rectangle(img_rgb, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0, 255, 0), 2)\n",
        "            label = f\"{data_config.get('names', ['class'])[cls]}: {conf:.2f}\"\n",
        "            cv2.putText(img_rgb, label, (bbox[0], bbox[1]-10), \n",
        "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "    \n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.imshow(img_rgb)\n",
        "    plt.title(f\"Predictions: {os.path.basename(image_path)}\", fontsize=14)\n",
        "    plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    \n",
        "    if save_path:\n",
        "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "    \n",
        "    plt.show()\n",
        "\n",
        "# Visualize a few sample predictions\n",
        "sample_images = test_images[:5]\n",
        "for img_file in sample_images:\n",
        "    img_path = os.path.join(test_images_dir, img_file)\n",
        "    results = model.predict(img_path, conf=0.25, iou=0.45, verbose=False)\n",
        "    save_path = f'{output_dir}/visualizations/{os.path.splitext(img_file)[0]}_pred.png'\n",
        "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "    visualize_predictions(img_path, results, save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Model Export"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exporting to ONNX format...\n",
            "Ultralytics 8.4.12  Python-3.13.5 torch-2.6.0+cu124 CPU (13th Gen Intel Core i9-13900H)\n",
            " ProTip: Export to OpenVINO format for best performance on Intel hardware. Learn more at https://docs.ultralytics.com/integrations/openvino/\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'sweetpotato_project\\runs\\segment\\sweetpotato_exp\\weights\\best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) ((1, 39, 8400), (1, 32, 160, 160)) (312.5 MB)\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['onnx>=1.12.0,<2.0.0', 'onnxslim>=0.1.71', 'onnxruntime-gpu'] not found, attempting AutoUpdate...\n",
            "Collecting onnx<2.0.0,>=1.12.0\n",
            "  Downloading onnx-1.20.1-cp312-abi3-win_amd64.whl.metadata (8.6 kB)\n",
            "Collecting onnxslim>=0.1.71\n",
            "  Downloading onnxslim-0.1.84-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting onnxruntime-gpu\n",
            "  Downloading onnxruntime_gpu-1.24.1-cp313-cp313-win_amd64.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\kensm\\anaconda3\\lib\\site-packages (from onnx<2.0.0,>=1.12.0) (1.26.4)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in c:\\users\\kensm\\anaconda3\\lib\\site-packages (from onnx<2.0.0,>=1.12.0) (5.29.3)\n",
            "Requirement already satisfied: typing_extensions>=4.7.1 in c:\\users\\kensm\\anaconda3\\lib\\site-packages (from onnx<2.0.0,>=1.12.0) (4.12.2)\n",
            "Collecting ml_dtypes>=0.5.0 (from onnx<2.0.0,>=1.12.0)\n",
            "  Downloading ml_dtypes-0.5.4-cp313-cp313-win_amd64.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: colorama in c:\\users\\kensm\\anaconda3\\lib\\site-packages (from onnxslim>=0.1.71) (0.4.6)\n",
            "Requirement already satisfied: packaging in c:\\users\\kensm\\anaconda3\\lib\\site-packages (from onnxslim>=0.1.71) (24.2)\n",
            "Requirement already satisfied: sympy>=1.13.1 in c:\\users\\kensm\\anaconda3\\lib\\site-packages (from onnxslim>=0.1.71) (1.13.1)\n",
            "Collecting flatbuffers (from onnxruntime-gpu)\n",
            "  Downloading flatbuffers-25.12.19-py2.py3-none-any.whl.metadata (1.0 kB)\n",
            "Collecting numpy>=1.23.2 (from onnx<2.0.0,>=1.12.0)\n",
            "  Downloading numpy-2.4.2-cp313-cp313-win_amd64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\kensm\\anaconda3\\lib\\site-packages (from sympy>=1.13.1->onnxslim>=0.1.71) (1.3.0)\n",
            "Downloading onnx-1.20.1-cp312-abi3-win_amd64.whl (16.4 MB)\n",
            "   ---------------------------------------- 0.0/16.4 MB ? eta -:--:--\n",
            "   ----- ---------------------------------- 2.1/16.4 MB 10.8 MB/s eta 0:00:02\n",
            "   --------- ------------------------------ 3.9/16.4 MB 9.7 MB/s eta 0:00:02\n",
            "   -------------- ------------------------- 6.0/16.4 MB 9.7 MB/s eta 0:00:02\n",
            "   ------------------- -------------------- 8.1/16.4 MB 10.0 MB/s eta 0:00:01\n",
            "   ------------------------ --------------- 10.2/16.4 MB 10.1 MB/s eta 0:00:01\n",
            "   ------------------------------ --------- 12.6/16.4 MB 10.3 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 14.9/16.4 MB 10.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 16.4/16.4 MB 10.4 MB/s eta 0:00:00\n",
            "Downloading onnxslim-0.1.84-py3-none-any.whl (234 kB)\n",
            "Downloading onnxruntime_gpu-1.24.1-cp313-cp313-win_amd64.whl (207.1 MB)\n",
            "   ---------------------------------------- 0.0/207.1 MB ? eta -:--:--\n",
            "   ---------------------------------------- 1.8/207.1 MB 10.2 MB/s eta 0:00:21\n",
            "    --------------------------------------- 3.7/207.1 MB 9.3 MB/s eta 0:00:22\n",
            "   - -------------------------------------- 5.8/207.1 MB 9.7 MB/s eta 0:00:21\n",
            "   - -------------------------------------- 7.9/207.1 MB 10.0 MB/s eta 0:00:21\n",
            "   - -------------------------------------- 10.0/207.1 MB 10.0 MB/s eta 0:00:20\n",
            "   -- ------------------------------------- 12.3/207.1 MB 10.1 MB/s eta 0:00:20\n",
            "   -- ------------------------------------- 14.4/207.1 MB 10.3 MB/s eta 0:00:19\n",
            "   --- ------------------------------------ 16.5/207.1 MB 10.3 MB/s eta 0:00:19\n",
            "   --- ------------------------------------ 18.9/207.1 MB 10.4 MB/s eta 0:00:19\n",
            "   ---- ----------------------------------- 21.0/207.1 MB 10.5 MB/s eta 0:00:18\n",
            "   ---- ----------------------------------- 23.3/207.1 MB 10.5 MB/s eta 0:00:18\n",
            "   ---- ----------------------------------- 25.7/207.1 MB 10.5 MB/s eta 0:00:18\n",
            "   ----- ---------------------------------- 27.8/207.1 MB 10.6 MB/s eta 0:00:17\n",
            "   ----- ---------------------------------- 30.1/207.1 MB 10.6 MB/s eta 0:00:17\n",
            "   ------ --------------------------------- 32.2/207.1 MB 10.6 MB/s eta 0:00:17\n",
            "   ------ --------------------------------- 34.3/207.1 MB 10.6 MB/s eta 0:00:17\n",
            "   ------- -------------------------------- 36.7/207.1 MB 10.6 MB/s eta 0:00:17\n",
            "   ------- -------------------------------- 38.8/207.1 MB 10.6 MB/s eta 0:00:16\n",
            "   ------- -------------------------------- 41.2/207.1 MB 10.6 MB/s eta 0:00:16\n",
            "   -------- ------------------------------- 43.5/207.1 MB 10.6 MB/s eta 0:00:16\n",
            "   -------- ------------------------------- 45.6/207.1 MB 10.6 MB/s eta 0:00:16\n",
            "   --------- ------------------------------ 47.7/207.1 MB 10.6 MB/s eta 0:00:16\n",
            "   --------- ------------------------------ 49.8/207.1 MB 10.5 MB/s eta 0:00:15\n",
            "   ---------- ----------------------------- 51.9/207.1 MB 10.5 MB/s eta 0:00:15\n",
            "   ---------- ----------------------------- 54.0/207.1 MB 10.5 MB/s eta 0:00:15\n",
            "   ---------- ----------------------------- 56.1/207.1 MB 10.5 MB/s eta 0:00:15\n",
            "   ----------- ---------------------------- 58.2/207.1 MB 10.5 MB/s eta 0:00:15\n",
            "   ----------- ---------------------------- 60.0/207.1 MB 10.4 MB/s eta 0:00:15\n",
            "   ----------- ---------------------------- 60.8/207.1 MB 10.2 MB/s eta 0:00:15\n",
            "   ------------ --------------------------- 62.1/207.1 MB 10.0 MB/s eta 0:00:15\n",
            "   ------------ --------------------------- 63.7/207.1 MB 9.9 MB/s eta 0:00:15\n",
            "   ------------ --------------------------- 65.3/207.1 MB 9.9 MB/s eta 0:00:15\n",
            "   ------------- -------------------------- 67.4/207.1 MB 9.9 MB/s eta 0:00:15\n",
            "   ------------- -------------------------- 69.5/207.1 MB 9.9 MB/s eta 0:00:14\n",
            "   ------------- -------------------------- 71.3/207.1 MB 9.9 MB/s eta 0:00:14\n",
            "   -------------- ------------------------- 73.4/207.1 MB 9.9 MB/s eta 0:00:14\n",
            "   -------------- ------------------------- 75.8/207.1 MB 9.9 MB/s eta 0:00:14\n",
            "   --------------- ------------------------ 77.9/207.1 MB 9.9 MB/s eta 0:00:13\n",
            "   --------------- ------------------------ 80.0/207.1 MB 10.0 MB/s eta 0:00:13\n",
            "   --------------- ------------------------ 82.3/207.1 MB 10.0 MB/s eta 0:00:13\n",
            "   ---------------- ----------------------- 84.4/207.1 MB 10.0 MB/s eta 0:00:13\n",
            "   ---------------- ----------------------- 86.8/207.1 MB 10.0 MB/s eta 0:00:12\n",
            "   ----------------- ---------------------- 88.9/207.1 MB 10.1 MB/s eta 0:00:12\n",
            "   ----------------- ---------------------- 91.0/207.1 MB 10.1 MB/s eta 0:00:12\n",
            "   ----------------- ---------------------- 93.1/207.1 MB 10.1 MB/s eta 0:00:12\n",
            "   ------------------ --------------------- 95.4/207.1 MB 10.1 MB/s eta 0:00:12\n",
            "   ------------------ --------------------- 97.5/207.1 MB 10.1 MB/s eta 0:00:11\n",
            "   ------------------- -------------------- 99.9/207.1 MB 10.1 MB/s eta 0:00:11\n",
            "   ------------------- ------------------- 102.0/207.1 MB 10.1 MB/s eta 0:00:11\n",
            "   ------------------- ------------------- 104.3/207.1 MB 10.1 MB/s eta 0:00:11\n",
            "   -------------------- ------------------ 106.4/207.1 MB 10.1 MB/s eta 0:00:10\n",
            "   -------------------- ------------------ 107.7/207.1 MB 10.1 MB/s eta 0:00:10\n",
            "   -------------------- ------------------ 109.1/207.1 MB 10.0 MB/s eta 0:00:10\n",
            "   -------------------- ------------------ 111.1/207.1 MB 10.0 MB/s eta 0:00:10\n",
            "   --------------------- ----------------- 113.0/207.1 MB 10.0 MB/s eta 0:00:10\n",
            "   --------------------- ----------------- 114.8/207.1 MB 10.0 MB/s eta 0:00:10\n",
            "   ---------------------- ----------------- 116.4/207.1 MB 9.9 MB/s eta 0:00:10\n",
            "   ---------------------- ----------------- 118.2/207.1 MB 9.9 MB/s eta 0:00:09\n",
            "   ----------------------- ---------------- 120.1/207.1 MB 9.9 MB/s eta 0:00:09\n",
            "   ----------------------- ---------------- 122.2/207.1 MB 9.9 MB/s eta 0:00:09\n",
            "   ------------------------ --------------- 124.5/207.1 MB 9.9 MB/s eta 0:00:09\n",
            "   ------------------------ --------------- 126.6/207.1 MB 9.9 MB/s eta 0:00:09\n",
            "   ------------------------ --------------- 129.0/207.1 MB 9.9 MB/s eta 0:00:08\n",
            "   ------------------------- -------------- 130.8/207.1 MB 9.9 MB/s eta 0:00:08\n",
            "   ------------------------- ------------- 133.2/207.1 MB 10.0 MB/s eta 0:00:08\n",
            "   ------------------------- ------------- 135.3/207.1 MB 10.0 MB/s eta 0:00:08\n",
            "   ------------------------- ------------- 137.6/207.1 MB 10.0 MB/s eta 0:00:07\n",
            "   -------------------------- ------------ 139.5/207.1 MB 10.0 MB/s eta 0:00:07\n",
            "   -------------------------- ------------ 141.6/207.1 MB 10.0 MB/s eta 0:00:07\n",
            "   --------------------------- ----------- 143.7/207.1 MB 10.0 MB/s eta 0:00:07\n",
            "   --------------------------- ----------- 146.0/207.1 MB 10.0 MB/s eta 0:00:07\n",
            "   --------------------------- ----------- 148.1/207.1 MB 10.0 MB/s eta 0:00:06\n",
            "   ---------------------------- ---------- 150.5/207.1 MB 10.0 MB/s eta 0:00:06\n",
            "   ---------------------------- ---------- 152.6/207.1 MB 10.0 MB/s eta 0:00:06\n",
            "   ----------------------------- --------- 154.7/207.1 MB 10.0 MB/s eta 0:00:06\n",
            "   ----------------------------- --------- 157.0/207.1 MB 10.0 MB/s eta 0:00:05\n",
            "   ----------------------------- --------- 159.1/207.1 MB 10.0 MB/s eta 0:00:05\n",
            "   ------------------------------ -------- 161.2/207.1 MB 10.1 MB/s eta 0:00:05\n",
            "   ------------------------------ -------- 163.6/207.1 MB 10.1 MB/s eta 0:00:05\n",
            "   ------------------------------- ------- 165.7/207.1 MB 10.1 MB/s eta 0:00:05\n",
            "   ------------------------------- ------- 167.8/207.1 MB 10.1 MB/s eta 0:00:04\n",
            "   -------------------------------- ------ 170.1/207.1 MB 10.1 MB/s eta 0:00:04\n",
            "   -------------------------------- ------ 172.2/207.1 MB 10.1 MB/s eta 0:00:04\n",
            "   -------------------------------- ------ 174.6/207.1 MB 10.1 MB/s eta 0:00:04\n",
            "   --------------------------------- ----- 176.7/207.1 MB 10.1 MB/s eta 0:00:04\n",
            "   --------------------------------- ----- 178.8/207.1 MB 10.1 MB/s eta 0:00:03\n",
            "   ---------------------------------- ---- 181.1/207.1 MB 10.1 MB/s eta 0:00:03\n",
            "   ---------------------------------- ---- 183.5/207.1 MB 10.2 MB/s eta 0:00:03\n",
            "   ---------------------------------- ---- 185.6/207.1 MB 10.2 MB/s eta 0:00:03\n",
            "   ----------------------------------- --- 187.7/207.1 MB 10.2 MB/s eta 0:00:02\n",
            "   ----------------------------------- --- 189.8/207.1 MB 10.2 MB/s eta 0:00:02\n",
            "   ------------------------------------ -- 191.9/207.1 MB 10.2 MB/s eta 0:00:02\n",
            "   ------------------------------------ -- 193.2/207.1 MB 10.1 MB/s eta 0:00:02\n",
            "   ------------------------------------ -- 194.8/207.1 MB 10.1 MB/s eta 0:00:02\n",
            "   ------------------------------------ -- 196.3/207.1 MB 10.1 MB/s eta 0:00:02\n",
            "   ------------------------------------- - 197.9/207.1 MB 10.0 MB/s eta 0:00:01\n",
            "   ------------------------------------- - 199.0/207.1 MB 10.0 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 199.5/207.1 MB 9.9 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 200.0/207.1 MB 9.8 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 200.8/207.1 MB 9.8 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 201.6/207.1 MB 9.7 MB/s eta 0:00:01\n",
            "   ---------------------------------------  202.1/207.1 MB 9.7 MB/s eta 0:00:01\n",
            "   ---------------------------------------  203.4/207.1 MB 9.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------  205.3/207.1 MB 9.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 207.1/207.1 MB 9.6 MB/s eta 0:00:00\n",
            "Downloading ml_dtypes-0.5.4-cp313-cp313-win_amd64.whl (212 kB)\n",
            "Downloading numpy-2.4.2-cp313-cp313-win_amd64.whl (12.3 MB)\n",
            "   ---------------------------------------- 0.0/12.3 MB ? eta -:--:--\n",
            "   ------ --------------------------------- 2.1/12.3 MB 10.2 MB/s eta 0:00:01\n",
            "   ------------- -------------------------- 4.2/12.3 MB 10.4 MB/s eta 0:00:01\n",
            "   ----------------- ---------------------- 5.2/12.3 MB 8.7 MB/s eta 0:00:01\n",
            "   ------------------ --------------------- 5.8/12.3 MB 7.5 MB/s eta 0:00:01\n",
            "   --------------------- ------------------ 6.6/12.3 MB 6.7 MB/s eta 0:00:01\n",
            "   ------------------------ --------------- 7.6/12.3 MB 6.5 MB/s eta 0:00:01\n",
            "   -------------------------- ------------- 8.1/12.3 MB 5.9 MB/s eta 0:00:01\n",
            "   ---------------------------- ----------- 8.9/12.3 MB 5.4 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 10.2/12.3 MB 5.5 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 11.8/12.3 MB 5.8 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 12.3/12.3 MB 5.8 MB/s eta 0:00:00\n",
            "Downloading flatbuffers-25.12.19-py2.py3-none-any.whl (26 kB)\n",
            "Installing collected packages: flatbuffers, numpy, onnxruntime-gpu, ml_dtypes, onnx, onnxslim\n",
            "\n",
            "  Attempting uninstall: numpy\n",
            "\n",
            "    Found existing installation: numpy 1.26.4\n",
            "\n",
            "   ------ --------------------------------- 1/6 [numpy]\n",
            "    Uninstalling numpy-1.26.4:\n",
            "   ------ --------------------------------- 1/6 [numpy]\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "   ------ --------------------------------- 1/6 [numpy]\n",
            "   ------ --------------------------------- 1/6 [numpy]\n",
            "   ------ --------------------------------- 1/6 [numpy]\n",
            "   ------ --------------------------------- 1/6 [numpy]\n",
            "   ------ --------------------------------- 1/6 [numpy]\n",
            "   ------ --------------------------------- 1/6 [numpy]\n",
            "   ------ --------------------------------- 1/6 [numpy]\n",
            "   ------ --------------------------------- 1/6 [numpy]\n",
            "   ------ --------------------------------- 1/6 [numpy]\n",
            "   ------ --------------------------------- 1/6 [numpy]\n",
            "   ------ --------------------------------- 1/6 [numpy]\n",
            "   ------ --------------------------------- 1/6 [numpy]\n",
            "   ------ --------------------------------- 1/6 [numpy]\n",
            "   ------ --------------------------------- 1/6 [numpy]\n",
            "   ------ --------------------------------- 1/6 [numpy]\n",
            "   ------ --------------------------------- 1/6 [numpy]\n",
            "   ------ --------------------------------- 1/6 [numpy]\n",
            "   ------ --------------------------------- 1/6 [numpy]\n",
            "   ------ --------------------------------- 1/6 [numpy]\n",
            "   ------ --------------------------------- 1/6 [numpy]\n",
            "   ------ --------------------------------- 1/6 [numpy]\n",
            "   ------ --------------------------------- 1/6 [numpy]\n",
            "   ------ --------------------------------- 1/6 [numpy]\n",
            "   ------ --------------------------------- 1/6 [numpy]\n",
            "   ------ --------------------------------- 1/6 [numpy]\n",
            "   ------ --------------------------------- 1/6 [numpy]\n",
            "   ------ --------------------------------- 1/6 [numpy]\n",
            "   ------ --------------------------------- 1/6 [numpy]\n",
            "   ------ --------------------------------- 1/6 [numpy]\n",
            "   ------ --------------------------------- 1/6 [numpy]\n",
            "   ------ --------------------------------- 1/6 [numpy]\n",
            "   ------ --------------------------------- 1/6 [numpy]\n",
            "   ------ --------------------------------- 1/6 [numpy]\n",
            "   ------ --------------------------------- 1/6 [numpy]\n",
            "   ------ --------------------------------- 1/6 [numpy]\n",
            "   ------ --------------------------------- 1/6 [numpy]\n",
            "   ------ --------------------------------- 1/6 [numpy]\n",
            "   ------ --------------------------------- 1/6 [numpy]\n",
            "   ------ --------------------------------- 1/6 [numpy]\n",
            "   ------ --------------------------------- 1/6 [numpy]\n",
            "   ------ --------------------------------- 1/6 [numpy]\n",
            "   ------ --------------------------------- 1/6 [numpy]\n",
            "   ------ --------------------------------- 1/6 [numpy]\n",
            "   ------ --------------------------------- 1/6 [numpy]\n",
            "   ------ --------------------------------- 1/6 [numpy]\n",
            "   ------ --------------------------------- 1/6 [numpy]  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\kensm\\anaconda3\\Lib\\site-packages\\~umpy'.\n",
            "  You can safely remove it manually.\n",
            "\n",
            "   ------------- -------------------------- 2/6 [onnxruntime-gpu]\n",
            "   ------------- -------------------------- 2/6 [onnxruntime-gpu]\n",
            "   ------------- -------------------------- 2/6 [onnxruntime-gpu]\n",
            "   ------------- -------------------------- 2/6 [onnxruntime-gpu]\n",
            "   ------------- -------------------------- 2/6 [onnxruntime-gpu]\n",
            "   ------------- -------------------------- 2/6 [onnxruntime-gpu]\n",
            "   ------------- -------------------------- 2/6 [onnxruntime-gpu]\n",
            "   ------------- -------------------------- 2/6 [onnxruntime-gpu]\n",
            "   ------------- -------------------------- 2/6 [onnxruntime-gpu]\n",
            "   ------------- -------------------------- 2/6 [onnxruntime-gpu]\n",
            "   ------------- -------------------------- 2/6 [onnxruntime-gpu]\n",
            "   ------------- -------------------------- 2/6 [onnxruntime-gpu]\n",
            "   ------------- -------------------------- 2/6 [onnxruntime-gpu]\n",
            "   ------------- -------------------------- 2/6 [onnxruntime-gpu]\n",
            "   ------------- -------------------------- 2/6 [onnxruntime-gpu]\n",
            "   ------------- -------------------------- 2/6 [onnxruntime-gpu]\n",
            "   ------------- -------------------------- 2/6 [onnxruntime-gpu]\n",
            "   ------------- -------------------------- 2/6 [onnxruntime-gpu]\n",
            "   ------------- -------------------------- 2/6 [onnxruntime-gpu]\n",
            "   ------------- -------------------------- 2/6 [onnxruntime-gpu]\n",
            "   -------------------- ------------------- 3/6 [ml_dtypes]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   -------------------------- ------------- 4/6 [onnx]\n",
            "   --------------------------------- ------ 5/6 [onnxslim]\n",
            "   --------------------------------- ------ 5/6 [onnxslim]\n",
            "   --------------------------------- ------ 5/6 [onnxslim]\n",
            "   --------------------------------- ------ 5/6 [onnxslim]\n",
            "   --------------------------------- ------ 5/6 [onnxslim]\n",
            "   --------------------------------- ------ 5/6 [onnxslim]\n",
            "   ---------------------------------------- 6/6 [onnxslim]\n",
            "\n",
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "numba 0.61.0 requires numpy<2.2,>=1.24, but you have numpy 2.4.2 which is incompatible.\n",
            "Successfully installed flatbuffers-25.12.19 ml_dtypes-0.5.4 numpy-2.4.2 onnx-1.20.1 onnxruntime-gpu-1.24.1 onnxslim-0.1.84\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success  54.6s\n",
            "WARNING \u001b[31m\u001b[1mrequirements:\u001b[0m \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.20.1 opset 12...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.84...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success  57.5s, saved as 'sweetpotato_project\\runs\\segment\\sweetpotato_exp\\weights\\best.onnx' (104.1 MB)\n",
            "\n",
            "Export complete (58.6s)\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\sweetpotato_project\\runs\\segment\\sweetpotato_exp\\weights\u001b[0m\n",
            "Predict:         yolo predict task=segment model=sweetpotato_project\\runs\\segment\\sweetpotato_exp\\weights\\best.onnx imgsz=640 \n",
            "Validate:        yolo val task=segment model=sweetpotato_project\\runs\\segment\\sweetpotato_exp\\weights\\best.onnx imgsz=640 data=C:\\Users\\kensm\\farm-photo-outliner\\sweetpotato_project\\dataset\\data.yaml  \n",
            "Visualize:       https://netron.app\n",
            "‚úì ONNX model exported to: sweetpotato_project\\runs\\segment\\sweetpotato_exp\\weights\\best.onnx\n",
            "\n",
            "Exporting to TorchScript format...\n",
            "Ultralytics 8.4.12  Python-3.13.5 torch-2.6.0+cu124 CPU (13th Gen Intel Core i9-13900H)\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'sweetpotato_project\\runs\\segment\\sweetpotato_exp\\weights\\best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) ((1, 39, 8400), (1, 32, 160, 160)) (312.5 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 2.6.0+cu124...\n",
            "\u001b[34m\u001b[1mTorchScript:\u001b[0m export success  4.5s, saved as 'sweetpotato_project\\runs\\segment\\sweetpotato_exp\\weights\\best.torchscript' (104.4 MB)\n",
            "\n",
            "Export complete (5.7s)\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\sweetpotato_project\\runs\\segment\\sweetpotato_exp\\weights\u001b[0m\n",
            "Predict:         yolo predict task=segment model=sweetpotato_project\\runs\\segment\\sweetpotato_exp\\weights\\best.torchscript imgsz=640 \n",
            "Validate:        yolo val task=segment model=sweetpotato_project\\runs\\segment\\sweetpotato_exp\\weights\\best.torchscript imgsz=640 data=C:\\Users\\kensm\\farm-photo-outliner\\sweetpotato_project\\dataset\\data.yaml  \n",
            "Visualize:       https://netron.app\n",
            "‚úì TorchScript model exported to: sweetpotato_project\\runs\\segment\\sweetpotato_exp\\weights\\best.torchscript\n",
            "\n",
            "Exporting ONNX with FP16 quantization...\n",
            "Ultralytics 8.4.12  Python-3.13.5 torch-2.6.0+cu124 CPU (13th Gen Intel Core i9-13900H)\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'sweetpotato_project\\runs\\segment\\sweetpotato_exp\\weights\\best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) ((1, 39, 8400), (1, 32, 160, 160)) (312.5 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.20.1 opset 12...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.84...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m converting to FP16...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success  4.1s, saved as 'sweetpotato_project\\runs\\segment\\sweetpotato_exp\\weights\\best.onnx' (52.1 MB)\n",
            "\n",
            "Export complete (5.3s)\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\sweetpotato_project\\runs\\segment\\sweetpotato_exp\\weights\u001b[0m\n",
            "Predict:         yolo predict task=segment model=sweetpotato_project\\runs\\segment\\sweetpotato_exp\\weights\\best.onnx imgsz=640 half\n",
            "Validate:        yolo val task=segment model=sweetpotato_project\\runs\\segment\\sweetpotato_exp\\weights\\best.onnx imgsz=640 data=C:\\Users\\kensm\\farm-photo-outliner\\sweetpotato_project\\dataset\\data.yaml half \n",
            "Visualize:       https://netron.app\n",
            "‚úì FP16 ONNX model exported to: sweetpotato_project\\runs\\segment\\sweetpotato_exp\\weights\\best.onnx\n"
          ]
        }
      ],
      "source": [
        "# Export to ONNX for edge deployment\n",
        "export_dir = f'{WORK_DIR}/exports'\n",
        "os.makedirs(export_dir, exist_ok=True)\n",
        "\n",
        "print(\"Exporting to ONNX format...\")\n",
        "onnx_path = model.export(format='onnx', imgsz=640, simplify=True, opset=12)\n",
        "print(f\"‚úì ONNX model exported to: {onnx_path}\")\n",
        "\n",
        "# Also export to TorchScript\n",
        "print(\"\\nExporting to TorchScript format...\")\n",
        "torchscript_path = model.export(format='torchscript', imgsz=640)\n",
        "print(f\"‚úì TorchScript model exported to: {torchscript_path}\")\n",
        "\n",
        "# Export with FP16 quantization for faster inference\n",
        "print(\"\\nExporting ONNX with FP16 quantization...\")\n",
        "onnx_fp16_path = model.export(format='onnx', imgsz=640, simplify=True, opset=12, half=True)\n",
        "print(f\"‚úì FP16 ONNX model exported to: {onnx_fp16_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì ONNX model inference successful!\n",
            "  Output shape: (1, 39, 8400)\n"
          ]
        }
      ],
      "source": [
        "# Test ONNX model inference\n",
        "try:\n",
        "    import onnxruntime as ort\n",
        "    \n",
        "    # Load ONNX model\n",
        "    session = ort.InferenceSession(onnx_path, providers=['CUDAExecutionProvider', 'CPUExecutionProvider'])\n",
        "    \n",
        "    # Test with a sample image\n",
        "    test_img_path = os.path.join(test_images_dir, test_images[0])\n",
        "    test_img = cv2.imread(test_img_path)\n",
        "    test_img = cv2.resize(test_img, (640, 640))\n",
        "    test_img = test_img.transpose(2, 0, 1)  # HWC to CHW\n",
        "    test_img = test_img.astype(np.float32) / 255.0\n",
        "    test_img = np.expand_dims(test_img, axis=0)\n",
        "    \n",
        "    # Run inference\n",
        "    input_name = session.get_inputs()[0].name\n",
        "    outputs = session.run(None, {input_name: test_img})\n",
        "    \n",
        "    print(f\"‚úì ONNX model inference successful!\")\n",
        "    print(f\"  Output shape: {outputs[0].shape}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ö† ONNX inference test failed: {e}\")\n",
        "    print(\"  Model exported but may need verification\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Download Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì Results packaged to: ./sweetpotato_project/sweetpotato_training_results.zip\n",
            "\n",
            "To download, run:\n",
            "from google.colab import files\n",
            "files.download('./sweetpotato_project/sweetpotato_training_results.zip')\n",
            "\n",
            "‚úì Results saved locally to: c:\\Users\\kensm\\farm-photo-outliner\\sweetpotato_project\\sweetpotato_training_results.zip\n",
            "  You can find all outputs in: c:\\Users\\kensm\\farm-photo-outliner\\sweetpotato_project\n"
          ]
        }
      ],
      "source": [
        "# Package all results for download\n",
        "results_zip = f'{WORK_DIR}/sweetpotato_training_results.zip'\n",
        "\n",
        "with zipfile.ZipFile(results_zip, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "    # Add best model\n",
        "    if os.path.exists(best_model_path):\n",
        "        zipf.write(best_model_path, 'best.pt')\n",
        "    \n",
        "    # Add ONNX models\n",
        "    if os.path.exists(onnx_path):\n",
        "        zipf.write(onnx_path, 'model.onnx')\n",
        "    if os.path.exists(onnx_fp16_path):\n",
        "        zipf.write(onnx_fp16_path, 'model_fp16.onnx')\n",
        "    \n",
        "    # Add predictions CSV\n",
        "    if os.path.exists(csv_path):\n",
        "        zipf.write(csv_path, 'predictions.csv')\n",
        "    \n",
        "    # Add training metrics\n",
        "    run_dir = f'{WORK_DIR}/runs/segment/sweetpotato_exp'\n",
        "    if os.path.exists(run_dir):\n",
        "        for root, dirs, files in os.walk(run_dir):\n",
        "            for file in files:\n",
        "                if file.endswith(('.png', '.jpg', '.csv', '.txt', '.json')):\n",
        "                    file_path = os.path.join(root, file)\n",
        "                    arcname = os.path.relpath(file_path, run_dir)\n",
        "                    zipf.write(file_path, f'results/{arcname}')\n",
        "\n",
        "print(f\"‚úì Results packaged to: {results_zip}\")\n",
        "print(f\"\\nTo download, run:\")\n",
        "print(f\"from google.colab import files\")\n",
        "print(f\"files.download('{results_zip}')\")\n",
        "\n",
        "# Download results\n",
        "if IS_COLAB:\n",
        "    from google.colab import files\n",
        "    files.download(results_zip)\n",
        "else:\n",
        "    print(f\"\\n‚úì Results saved locally to: {os.path.abspath(results_zip)}\")\n",
        "    print(f\"  You can find all outputs in: {os.path.abspath(WORK_DIR)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Training Summary\n",
        "\n",
        "### Model Performance\n",
        "- **Best mAP@0.5**: Check validation metrics above\n",
        "- **Model Size**: Check model parameters above\n",
        "- **Inference Speed**: Run speed benchmark below\n",
        "\n",
        "### Files Generated\n",
        "- `best.pt`: Best trained model weights\n",
        "- `model.onnx`: ONNX export for deployment\n",
        "- `predictions.csv`: All predictions with bboxes and masks\n",
        "- `low_confidence_predictions.csv`: Images flagged for re-annotation\n",
        "- Training logs and visualizations in `runs/segment/sweetpotato_exp/`\n",
        "\n",
        "### Next Steps\n",
        "1. Review low-confidence predictions for active learning\n",
        "2. Fine-tune hyperparameters if mAP < 0.85\n",
        "3. Test ONNX model on edge devices\n",
        "4. Compare with Mask R-CNN baseline (see comparison notebook)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Benchmarking inference speed (100 runs)...\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "Results saved to \u001b[1mC:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\u001b[0m\n",
            "2 labels saved to C:\\Users\\kensm\\farm-photo-outliner\\runs\\segment\\sweetpotato_project\\outputs\\predictions\\predictions\\labels\n",
            "\n",
            "‚úì Average inference time: 51.84 ms\n",
            "‚úì FPS: 19.29\n",
            "‚úì Below real-time requirement (30+ FPS)\n"
          ]
        }
      ],
      "source": [
        "# Inference speed benchmark\n",
        "import time\n",
        "\n",
        "test_img_path = os.path.join(test_images_dir, test_images[0])\n",
        "num_runs = 100\n",
        "\n",
        "print(f\"Benchmarking inference speed ({num_runs} runs)...\")\n",
        "\n",
        "# Warmup\n",
        "for _ in range(10):\n",
        "    _ = model.predict(test_img_path, verbose=False)\n",
        "\n",
        "# Benchmark\n",
        "start_time = time.time()\n",
        "for _ in range(num_runs):\n",
        "    _ = model.predict(test_img_path, verbose=False)\n",
        "end_time = time.time()\n",
        "\n",
        "avg_time = (end_time - start_time) / num_runs\n",
        "fps = 1.0 / avg_time\n",
        "\n",
        "print(f\"\\n‚úì Average inference time: {avg_time*1000:.2f} ms\")\n",
        "print(f\"‚úì FPS: {fps:.2f}\")\n",
        "print(f\"‚úì {'Meets' if fps >= 30 else 'Below'} real-time requirement (30+ FPS)\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
